<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[函数式编程（Ocaml）ch1]]></title>
    <url>%2F2021%2F04%2F20%2F%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%EF%BC%88Ocaml%EF%BC%89ch1%2F</url>
    <content type="text"><![CDATA[Abstract 介绍完Ocaml的基本概念，这一章来回顾一点高中数学知识——Proofs By Induction-归纳证明。PL中的很多理论都会用到归纳法。 Mathematical induction $\Rightarrow$ xx Complete inductionStructural induction]]></content>
      <categories>
        <category>Ocaml</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>FP</tag>
        <tag>Proofs by Induction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数式编程（Ocaml）ch0]]></title>
    <url>%2F2021%2F04%2F18%2F%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%EF%BC%88Ocaml%EF%BC%89ch0%2F</url>
    <content type="text"><![CDATA[Abstract ​ 最近在实验室实习的过程中学到了很多有意思的东西，对Programming Languages也有了更深的了解，Ocaml是一门支持多范式的函数式编程语言。程序描述计算，但是又不仅仅是计算。Ocaml的学习带给我的不仅仅是语言本身，这个系列记录了其中的部分心得: 关于scripting/imperative/object-oriented/functional PL的基本概念 Higher-order Functions State-Full vs State-Free Computation Modelling Objects and Closures Exceptions/Continuations to Defer Control Polymorphism Partial Evaluation/Lazy Programming/Modules 关于reason about programs的方法 Type Checking Induction Operational Semantics QuickCheck 关于设计一门语言的基本规则 FP’s Basic Concepts Ocaml is a statically typed functional programminng language。函数式编程中，function永远是一等公民，程序中只有expression的概念，通过functions递归处理values来完成computations。Ocaml通过pattern matching模式匹配的方式来定义递归数据结构和函数，进而写出更简洁的程序。 在函数式中还有一个和imperative PL.中不同的概念称为effect-free programming。在命令式语言中，我们通过给variables/fields赋值来修改程序状态并将赋值行为的结果看成是effects。但是比如函数式就不会explicitly的分配内存，甚至没有exception handling来改变控制流状态——不支持effect被称为pure functiional比如Haskell。Ocaml不是纯函数式语言。所以支持effectful/state-full programming和pure FP。 最后一个关键字就是statically typed静态类型。Types statically approximate the runtime behaviour of an expression.意思就是static type checking本身是在程序运行之前进行类型检查——通过syntatic structure of expressions。它可以保证通过静态类型检查的程序在运行时一定不会core dump。这样的statically typed PL.比如Ocaml/Java/ML/Haskell/Scala等也被称为是type-safe的。 Expressions, Names, Values and Types 在函数式中没有语句statements，最基本的expression就是numbers/strings/booleans。 12345&gt; # 2 + 3;;&gt; - : int = 5&gt; # 4.0 /. 2.0;;&gt; - : float = 2.0&gt; &gt; 上面代码中的格式为&lt;name&gt; : &lt;type&gt; = &lt;value&gt; 。我们将;;之前的式子称为expressions，将整个计算过程称为evaluation，而将计算的结果称为values。 注意在Ocaml中基础运算符并没有被重载，故浮点运算都是在后面有一个,。这主要是因为Ocaml是静态类型的，不会在运行时去根据运算符参数来推导重载的operators。 通过类型检查的程序，其evaluation要么更新到一个新的state要么报一个built-in runtime error。比如: 123&gt; # 3 / 0;;&gt; Exception: Division_by_zero&gt; Variables, Bindings and Functions Ocaml是一个call-by-value的语言——it binds values to variable names not expressions。这里有一个binding的概念，区分于assignment。我们只是在values和name之间建立了“链接”——并没有新的state被创建——我理解和imperative PL.不同的应该是内存模型比如C中对局部变量是放在栈上的但是确实创建了内存。当然这种“链接”也是可以更新的。在Ocaml中用let表达式来建立一个绑定。 12345&gt; # let x = 3 * 3;;&gt; val x : int = 9&gt; # let x = 42;;&gt; val x : int = 42&gt; &gt; 变量的作用域是根据binding stack来确定的。局部或者临时创建的binding都会被push进binding stack中，在不需要的时候会被GC清除。 1234567&gt; # let k = 4;;&gt; val k : int = 4&gt; # let k = 3 in k * k ;;&gt; - : int = 9&gt; # k;;&gt; - : int = 4&gt; &gt; 这里有一个新的let &lt;name&gt; = &lt;expression 1&gt; in &lt;expression 2&gt;结构——将expression1的value绑定到name上，然后继续使用这个新的绑定对expression 2进行evalutions。 在函数式中let不仅可以绑定基本类型，还可以绑定函数。 12345&gt; let area : float -&gt; float = function r -&gt; pi *. r *. r;;&gt; let area : float -&gt; float = fun r -&gt; 3.14 *. r *. r;;&gt; let area (r:float) = pi *. r *. r;;&gt; let a1 = area(2.0);;&gt; &gt; 上面的三种写法是等价的，都得到函数类型val area : float -&gt; float = &lt;fun&gt;。有意思的是函数作为一种绑定，也是在binding stack中的，所以它只能看到过去的绑定： 1234567891011&gt; # let (pi*float) = 3.0&gt; val pi : float = 3.14&gt; # let area (r:float) = pi *. r *.r;;&gt; val area : float -&gt; float = &lt;fun&gt;&gt; # let a1 = area(2.0);;&gt; val a1 : float = 12.0&gt; # let (pi*float) = 4.0&gt; val pi : float = 4.0&gt; # let a2 = area(2.0);;&gt; val a2 : float = 12.0&gt; &gt; 最后介绍一下递归函数。在Ocaml中递归函数使用let rec来声明。比如定义factorial: 123456&gt; # exception Domain;;&gt; # let rec fact n = &gt; if n &lt; 0 then raise Domain&gt; else if n = 0 then 1&gt; else n * fact(n - 1);;&gt; &gt; 在函数式中所有的函数都可以被写成尾递归的形式然后进一步优化——这是因为尾递归函数的栈帧可以被优化掉。比如: 123456&gt; # let fact_tr n = &gt; let rec f n acc = &gt; if n = 0 then acc else f (n - 1) (n * acc)&gt; in&gt; f n 1&gt; Data Types and Pattern Matching 这一节可以在Ocaml中定义自己的递归/非递归的数据类型。 Ocaml使用type来定义有限无序的非递归集合，这里举一个扑克牌的例子: 123456789101112&gt; # type suit = Clubs | Spades | Hearts | Diamonds;;&gt; type suit = Clubs | Spades | Hearts | Diamonds&gt; # type rank = Two | Three | Four | Five | Six | Seven | Eight | Nine | Ten | Jack | Queen | King | Ace;;&gt; # type card = rank * suit;;&gt; type card = rank * suit&gt; # type hand = Empty | Hand of card * hand;;&gt; type hand = Empty | Hand of card * hand&gt; # let rec dom (s1, s2) = match (s1, s2) with &gt; | (Spades, _) -&gt; true&gt; | (Hearts, Diamonds) -&gt; true&gt; | (s1, s2) -&gt; s1 = s2&gt; &gt; Ocaml使用pattern matching模式匹配来操作这些数据结构。这里有两个概念——patterns和constructors。每一个pattern由不同的constructors填充——这里的构造器指的是每一个和类型元素同名的构造器比如Clubs。Ocaml规定构造器首字母必须大写，且匹配是从上到下的顺序。 进一步的，为了简化代码而支持inductively的deep pattern构造形式如下: 12345&gt; # let rec add c1 c2 = match c1 c2 with&gt; | (Hearts, v1), (Hearts, v2) -&gt; v1 + v2&gt; | _, _ -&gt; 0;;&gt; val add : ('a -&gt; (suit * int) * (suit * int)) -&gt; 'a -&gt; int = &lt;fun&gt;&gt; &gt; 这里会发现构造了一个比较复杂的类型(&#39;a -&gt; (suit*int)*(suit*int)) -&gt; &#39;a -&gt; int。其中type1 * type2为一个pair，而`a为任意类型。 上述函数的基本类型推导过程为两个任意类型为输入参数，int为输出。其中任意类型为(suit*int)*(suit*int)的。 上面扑克牌的例子中hand定义一组无限递归集合。在hand类型中，Empty和Hand分别为两个constructors。Empty没有输入参数，而Hand以a tuple of a card and another hand的一个tuple为输入参数。看下面的实例化例子: 12345678910&gt; # let hand0: hand = Empty&gt; let hand1: hand = Hand((Ace, Hearts), Empty)&gt; let hand2: hand = Hand((Queen, Diamonds), hand1)&gt; let hand3:hand = &gt; Hand((Ace, Spades),&gt; Hand((Ten, Diamonds), &gt; Hand((Seven, Clubs),&gt; Hand((Queen, Spades),&gt; Hand((Eight, Clubs), Empty)))));;&gt; &gt; 这个hand类型实际上就是一棵退化的二叉树（只能靠右生长）——叶子是Empty， 而Hand构造器使用两个参数来建树。 下面我们定义一个函数，这里函数的类型是suit -&gt; hand -&gt; hand，功能是给定一个suit -&gt; hand的输入，然后从hand中找有匹配到suit类型的hand然后返回。 123456&gt; # let rec extract (s:suit) (h:hand) = match h with &gt; | Empty -&gt; Empty&gt; | Hand ((_, s') as c, h') -&gt;&gt; if s = s' then Hand(c, extract s h')&gt; else extract s h'&gt; &gt; 上一个函数中的Empty实际上就是一个终结符，意味着如果hand类型都不匹配的话就直接返回Empty。但是如果我要匹配一个card的话，没有匹配上该怎么返回呢？Ocaml引入一个optional data type。比如下面的函数: 12345678&gt; # type 'a option = None | Some of 'a&gt; type 'a option = None | Some of 'a&gt; # let rec find (r, h) = match h with&gt; | Empty -&gt; None&gt; | Hand((r', s'), h') -&gt; if r = r' then Some s'&gt; else find(r, h')&gt; val find: rank * hand -&gt; suit option = &lt;fun&gt;&gt; &gt; 其中option type表示由Some构造器实现的类型为`a的元素集合，是符合多态的任意类型。]]></content>
      <categories>
        <category>Ocaml</category>
      </categories>
      <tags>
        <tag>PL</tag>
        <tag>FP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lisp语言和Emacs]]></title>
    <url>%2F2021%2F02%2F16%2FLisp%E8%AF%AD%E8%A8%80%E5%92%8CEmacs%2F</url>
    <content type="text"><![CDATA[Abstract ​ 第一次接触EMACS是大二的时候，当时只顾着新奇的界面和强大的功能却忽视了其背后真正的理论。后来我写代码也一直不喜欢IDE这种东西，但现在回过头来看，这貌似也只是一种浮于表面而无关原理的执拗。 ​ 这次重新回归到Spacemacs，我希望仔细从Lisp的角度理解这款编辑器，不管是其插件特性还是语言本身。]]></content>
      <categories>
        <category>Lisp</category>
      </categories>
      <tags>
        <tag>EMACS</tag>
        <tag>PL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebAssembly和Wabt]]></title>
    <url>%2F2020%2F11%2F12%2FWebAssembly%E5%92%8CWabt%2F</url>
    <content type="text"><![CDATA[Abstract 最近参加deeplang的的过程中，接触到了一些编译领域的新技术，总结一下希望有时间了可以进一步的深入了解。参考资料是WebAssembly标准入门。 Points 过去很多技术尝试将C/C++程序直接运行在浏览器中，比如TypeScript 将C/C++代码转换为JS。 Emscripten 而这个项目利用LLVM编译器前端编译C/C++代码，生成LLVM平台特有的跨平台中间语言代码，最终再将IR转换为JavaScript的asm.js子集——这是WebAssembly的基础。 AOT编译 JIT编译 JIT的优点在于Profile-Based Optimization，根据运行时信息然后随着时间的推移尽可能的得到最优的代码。 而AOT的优点在于无需runtime运行，直接静态链接至最终的程序中。 WebAssembly JavaScript运行在其虚拟机上，而WebAssembly也运行在其虚拟机上。而现在Node.js 8.0之后的版本也可以运行WebAssembly——也就是说WebAssembly虚拟机可以脱离JS的环境支持，不仅仅运行在浏览器中。 WebAssembly概述 和LLVM IR很像，有两种汇编表示——.wat文本表示和.wasm机器表示。 关键概念 模块 由.wasm编译而来的可执行机器码的二进制对象。 内存 网页环境下，wasm的内存由JavaScript中的ArrayBuffer对象实现的。 表格 引入表格对象用于存储函数引用来模拟C/C++指针。 实例 导入对象 调用JS函数 导出对象 提供接口 指一个模块及其运行时的所有状态，包括内存，表格以及导入对象等。模块只有被实例化之后才可以调用。 程序生命周期 将wat或者其他语言编译成.wasm文件 网页中使用fetch等获取.wasm文件 emrun --no_browser --port 8080 . 将文件运行在http协议上 然后打开http://localhost:8080/xxx.html 将.wasm编译为模块，编译过程中进行合法性检查 实例化，初始化导入对象，创建模块实例 执行实例的导出函数，完成操作 虚拟机体系结构 一个全局类型数组(函数签名) 一个全局函数数组 一个全局变量数组 一个全局表格对象(元素引用) 一个全局内存对象 一个运行时栈 Hello World JavaScript部分hello.html 12345678910111213141516171819202122232425&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Show me the answer&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; var wasmMem = new WebAssembly.Memory(&#123;initial:1&#125;); function printStr(offset, length)&#123; var bytes = new Uint8Array(wasmMem.buffer, offset, length); var string = new TextDecoder('utf-8').decode(bytes); console.log(string); &#125;; var importObj = &#123;js : &#123;print: printStr, mem: wasmMem&#125;&#125;; fetch('hello.wasm').then(response=&gt; response.arrayBuffer() ).then(bytes=&gt; WebAssembly.instantiate(bytes, importObj) ).then(result =&gt; result.instance.exports.hello() ); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; wat部分hello.wat 12345678910111213 ;; hello.wat(module ;; import js::print as js_print(); (import "js" "print" (func $js_print (param i32 i32))) (import "js" "mem" (memory 1)) ;;import js::mem as memory (data (i32.const 0) "你好，wasm") (func (export "hello") i32.const 0 ;; pass offset 0 to js_print i32.const 13 ;; pass offset 13 to js_print call $js_print ) ) 首先将.wat编译成为.wasm,需要用到wabt工具集。还需要下载 Emscripten工具集。编译好之后配置环境变量。就可以执行了。 12$ wat2wasm hello.wat -o hello.wasm$ emrun --no_browser --port 8080 . 然后打开http://localhost:8080/xxx.html，启动Chrome下的开发者模式，看到执行成功。 WebAssembly核心在JS环境中 浏览器中的wasm运行在JS虚拟机上，页面可以通过一组JS对象进行wasm模块的编译，载入，配置，调用等操作。 在wasm中的几个关键概念都有与之对应的对象： 模块——WebAssembly.Module 内存——WebAssembly.Memory 表格——WebAssembly.Table 实例——WebAssembly.Instance WebAssembly汇编语言]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>Compiler</tag>
        <tag>PL</tag>
        <tag>WebAssembly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LLVM漫谈（2-Implementing a Language）]]></title>
    <url>%2F2020%2F07%2F07%2FLLVM%E6%BC%AB%E8%B0%88%EF%BC%882-Implementing-a-Language%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Abstract 基于LLVM实现简单的编程语言kaleidoscope，来源于LLVM9.0.0 tutorial。 LLVM的官方文档还是很不错的，阅读完其中的tutorials就能大致上手LLVM了。实现的代码对C++11要求比较高，我放在了Github上。 实现共分为10部分： 实现词法分析器Lexer 使用递归下降和运算符优先级解析实现语法分析器Parser 将AST转化成LLVM-IR 添加JIT即时编译和优化器的支持 扩展——控制流，这一章会引入SSA概念 扩展——用户定义运算符 扩展——自动变量，深入SSA 目标代码生成 扩展——添加调试器 深入——GC，异常等 Parser编译原理C++原理LLVM-IR]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LLVM漫谈（1-LLVM编译框架）]]></title>
    <url>%2F2020%2F06%2F25%2FLLVM%E6%BC%AB%E8%B0%88%EF%BC%881-LLVM%E7%BC%96%E8%AF%91%E6%A1%86%E6%9E%B6%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Abstract LLVM，这个星球最牛逼的编译器。 其核心设计理念就是统一的底层中间表达以及模块化的软件工程化方法。LLVM采用了前端-优化器-后端的组织形式，只是不同的前端和后端都采用统一的底层中间表示格式（LLVM IR）来最大可能复用优化器的代码。 在Chris Lattner将其开源后，LLVM逐渐发展成为了成熟的编译框架，具有大量库和编译链工具。 我使用的平台是macOS Mojave 10.14，在编译的时候要注意版本是否兼容。 一般系统会通过打印二进制文件名称和无法加载的动态库的名称来发现链接错误。当屏幕上打印动态库名称时要予以注意，这说明系统动态链接器和加载器无法加载该库，因为该程序与当前系统不兼容。 我编译LLVM 10.0.0的时候出错如下： 后来发现这个版本的Xcode工具链最高只支持LLVM 9.0.0版本，然后换了版本最后编译成功。 BUILD Subproject Deployed On My System Note llvm-core modern source- and target-independent optimizer, along with code generation support for many popular CPUs Clang “LLVM native” C/C++/Objective-C compiler front-end LLDB native debugger LLD native linker libcxx/libcxxabi standard conformant and high-performance implementation of the C++ Standard Library, compiler-rt highly tuned implementations of the low-level code generator support routines and implementations of run-time libraries llvm 以上的subproject通过以下编译方式完成部署： 12345678//ought to download source of subprojects to local, besides $ git clone https://github.com/llvm/llvm-project.git $ mkdir /LLVM/llvm-build &amp;&amp; cd //LLVM/llvm-build$ cmake -G Ninja -DLLVM_ENABLE_PROJECTS='lldb;clang;compiler-rt;lld;' \ -DCMAKE_INSTALL_PREFIX='/LLVM/llvm-install' \ ~/where you put llvm-src$ ninja &amp;&amp; ninja install$ echo $? //check libcxx/libcxxabi 这里理清楚一个概念： glic是linux最重要的运行库，其实现最底层的API供其他库使用比如malloc/printf等。 libstdc++是一个C++标准库，如果跑在linux则依赖Glibc libcxx是LLVM专门开发的一个代替libstdc++的c++标准库 compiler-rt是LLVM开发来替代libgcc,主要用于为硬件不支持的低级功能提供特定于目标的支持 clang++构建可执行文件的时候使用libcxx或者libclc(OpenCL运行时库)。其中libcxx实现由库本身和一个低级函数层libcxxabi组成，这个函数层用来处理异常和运行时类型信息(RTTI)等功能，这种分离式设计使得libcxxabi更容易移植。 1234567891011$ git clone https://github.com/llvm/llvm-project.git$ cd llvm-project$ mkdir /LLVM/libcxx-build &amp;&amp; cd /LLVM/libcxx-build$ cmake -G Ninja -DCMAKE_C_COMPILER=clang \ -DCMAKE_CXX_COMPILER=clang++ \ -DLLVM_ENABLE_PROJECTS="libcxx;libcxxabi" \ -DCMAKE_INSTALL_PREFIX='/LLVM/llvm-install' \ ~/where you put libcxx-src$ make # Build$ make check-cxx # Test$ make install-cxx install-cxxabi # Install warning 其中llvm和libcxx我是分开编译的，而且编译目录和安装目录都是指定的目录，默认很可能会安装到系统路径下，从而带来错误。 ~/Document/LLVM9.0.0/ llvm //llvm源代码 libcxx //libcxx源代码 /LLVM/ llvm-build //llvm编译路径 llvm-install //llvm安装路径 /LLVM/ libcxx-build //libcxx编译路径 libcxx-install //libcxx安装路径 Features核心设计 LLVM中最核心的就是LLVM-IR ： SSA表示和允许快速优化的无限寄存器 通过将整个程序存储在磁盘IR表示中，实现便捷的链接时优化 当然LLVM不仅仅只有一种中间表示形式： 将C或C++转换为LLVM-IR的时候，Clang将使用抽象语法树AST结构在内存中表示程序 将LLVM-IR转换为特定于机器的汇编语言的时候，LLVM首先将程序转换为有向无环图DAG格式以便进行指令选择，然后将其转换回三地址表示以进行指令调度 为了实现汇编器和链接器，LLVM使用第四种中间数据结构MCModule在对象文件的上下文中保存成程序表示 在整个框架中，”库”是一个很核心的概念。很多二进制工具都可以直接调用库来实现。而Clang作为编译驱动程序则可以通过链接小工具的库来实现其功能——代码重用。故clang在二进制文件中是最大的，因为它链接并利用了整个LLVM生态系统。而开发者一般都是将LLVM各个组件看出是库。 编译流程clang clang作为编译器驱动程序隐式的调用从前端到链接器的所有工具。整个过程都是在内存中完成的，并不会将中间文件输出到磁盘中。 12$ clang hello.c -o hello$ clang -### hello.c -o hello //可以查看驱动程序调用的所有工具 独立工具 LLVM独立工具会将中间文件输出到磁盘上。 Tools Notes opt 在IR级别对程序进行优化的工具，输入必须是LLVM位码文件(编码的LLVM-IR)，并且生成的输出文件必须具有相同的类型 llc 通过特定后端将LLVM位码转换为目标机器汇编语言文件或目标文件的工具，可以通过传递参数来选择优化级别，打开调试选项以及启用或禁用特定与目标的优化 llvm-mc 能够汇编指令并生成诸如ELF,Mach-O,PE等对香格式的可执行目标文件，也可以反汇编相同的对象，从而转储这些指令的汇编信息和内部LLVM机器指令数据结构 lli 是LLVM IP的解释器和JIT编译器 llvm-link 将几个LLVM位码链接在一起，以产生一个包含所有输入的LLVM位码 llvm-as 将人工可读的LLVM-IR文件(称为LLVM汇编码)转换为LLVM位码 llvm-dis 将LLVM位码解码成为LLVM汇编码 -emit-llvm LLVM位码： 编码的LLVM-IR LLVM汇编码： 人工可读的LLVM-IR 假设main.c和sum.c: 123456789101112131415161718$ vim main.c#include&lt;stdio.h&gt; int main(void) &#123; int r = sum(3, 4); printf("r = %d\n", r); return 0;&#125;$ vim sum.c int sum(int x, int y) &#123; return (x + y);&#125; 如果直接使用编译器驱动程序Clang的话： 1$ clang main.c sum.c -o sum 如果使用独立工具的话: 12$ clang -emit-llvm -c main.c -o main.bc$ clang -emit-llvm -c sum.c -o sum.bc 其中-emit-llvm编译选项可以让clang根据-c或者-S参数来生成LLVM位码还是LLVM汇编码。 -c 生成LLVM位码 -c -S生成LLVM汇编码 12$ clang -emit-llvm -c -S main.c -o main.ll$ clang -emit-llvm -c -S sum.c -o sum.ll llc 该工具从每个LLVM位码文件内生成特定于目标的可重定位目标文件，并通过将其链接到系统链接器来构建可执行文件 123$ llc -filetype=obj main.bc -o main.o$ llc -filetype= obj sum.bc -o sum.o$ clang main.o sum.o -o sum llvm-link 该工具将多个LLVM位码文件连接成为最终的LLVM位码文件 123$ llvm-link main.bc sum.bc -o sum.linked.bc$ llc -filetype=obj sum.linked.bc -o sum.linked.o$ clang sum.linked.o -o sum 可以看到所有的二进制工具都围绕几个中间形式的表示展开，这些中间表示在编译过程中占很重要的作用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LLVM漫谈（0-编译系统概述）]]></title>
    <url>%2F2020%2F06%2F02%2FLLVM%E6%BC%AB%E8%B0%88%EF%BC%880-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Abstract 从开始接触编译系统的学习已经快半年了，有些心得总结一下。 什么是编译系统？我想从两个角度谈一下： 首先从技术角度来讲，广义的编译系统负责将高级语言转换成为CPU可执行的二进制机器代码。编译系统包括编译器， 汇编器，静态/动态链接器，操作系统装载器以及运行库。 编译器： 是系统前半部分的核心，负责将源文件.c转换成为汇编文件.s。 汇编/链接/装载器：是系统后半部分的核心，主要是将.s转换为二进制ELF文件并进一步围绕ELF处理。 运行库：是操作系统层面用来支持高级语言运行环境比如内存池，标准API等的库文件。 然后从专业的角度来讲，我觉得可以分为系统层面和算法优化层面，系统层面主要是整个编译框架比如LLVM，核心是和操作系统交互的部分，这部分内容是编译器工程师的基本功，需要掌握细节。而算法优化层面指的是编译优化——编译器工程师的最理想的方向就是做优化，这一部分需要精通，从静态单赋值SSA等传统的静态分析优化到现在主流的深度学习推理引擎比如TVM等。 本文主要是对系统层面的学习，对系统层面的学习止步于对LLVM编译框架的使用和源代码阅读。 思路 本文主要分为三个部分，编译，ELF以及库文件。 首先简单介绍一下编译器的整体框架和编译流程。 核心部分是学习*nix操作系统下的ELF文件的格式——普通c/c++高级程序在目标文件中是如何存储的；目标文件是如何被链接器链接在一起，并且形成可执行文件的过程。目标文件在链接时符号处理，重定位和地址分配如何进行。可执行文件如何被装载并且执行，可执行文件与进程的虚拟空间之间如何映射。讲解动态链接。 最后讲解一下运行库的原理和操作系统与编译系统交互的部分。 编译器 编译器分为前端和后端，直观上讲就是将源语言形式化的表示并翻译成为汇编目标语言。前端主要有： 词法分析器 语法分析器， 语义分析器 等完成源语言的语法推导，语义处理，然后将特定信息收集到符号表中，不同的编译器前端会生成不同的中间表示——比如LLVM IR就是一种非常重要的中间代码。 后端主要是： 寄存器分配 指令选择 指令调度 后端和目标机的关系比较紧密，也是优化的重点平台。 汇编器 当编译器将源文件翻译成为汇编语言之后，.s文件需要进一步的被汇编器进行转换成为可重定位目标文件（Relocatable File）。 因为汇编语言本质上就是助记符，汇编器就是将汇编文件翻译成为机器可执行的初步的二进制文件，这里的初步是汇编器汇编之后生成的.o文件还不能直接在操作系统中运行，这是因为.o文件中很多符号和变量的地址都没有确定——属于相对地址，所以无法加载到进程地址空间中，而且其运行还需要操作系统提供的运行库提供支持，这一切都需要链接器来完成。所以.o文件又称为可重定位目标文件。 从.s文件翻译成为.o文件，必须按照特定指令集的机器码，还有ELF文件的格式来转换，实现起来不是很难——需要精通目标机器的体系结构，以及目标机器的ELF文件格式。这里不涉及体系结构的知识。 ELFELF简介 其实从汇编器的实现中就已经用到了ELF的知识。 ELF可以说是编译系统工具链中的最重要的文件格式了，离开编译器之后的所有编译步骤几乎都和ELF相关或者围绕ELF展开，所以对它的研究非常有意义。 最早是由Unix System V Release3提出了COFF的概念以及使用规范。后来Windows基于COFF指定了PE格式标准，而Linux也以ELF作为基本格式。COFF的主要贡献就是提供了“段segment”的概念。 ELF类型 根据ELF文件标准，可以分为下面4类： ELF文件类型 说明 实例 可重定位目标文件(Relocatable File) 由汇编器生成的.o文件，又被称为目标文件，因为需要连接重定位其文件中的符号地址所以叫Relocatable；另外，静态链接库.a其实也是使用ar程序将很多.o文件压缩并对其进行索引和编号。所以也算此类型。 Linux下的.o文件，.a静态库文件；Windows下的.obj，.lib静态库文件 可执行文件(Executable File) 是可以直接执行的程序，又被称为可执行文件。 /usr/bash文件；Windows下的.exe 共享目标文件(Shared Object File) 共享就是动态链接的本质。其可以被链接器继续链接生成新的目标文件；也可以和可执行文件结合，作为进程映像的一部分来运行。 Linux下的.so；Windows下的DLL 核心转储文件(Core Dump File) 当进程意外终止的时候，系统可以将该进程的地址空间及终止时的一些其他信息转储到核心转储文件中。 Linux下的core dump ELF格式分段 以目标文件.o为例介绍，目标文件中的内容至少含有编译后的机器指令代码和数据。按照COFF的历史规定，ELF格式也是按照段-segment来管理的。下面是ELF文件的基本格式： 从图中可以看到，ELF的开头是ELF Header，描述了整个文件的文件属性，包括文件是否可执行，是静态链接还是动态链接及入口地址（如果是可执行文件的话），目标硬件，操作系统等信息。ELF中第二重要的数据结构是Section Header table——描述文件中各个段的数组。段表描述了文件中各个段在文件中的偏移量以及段的属性等，从其中可以得到每个段的所有信息。ELF Header后面就是各个段的内容。分段的目的如下： 当指令和数据分离的时候，操作系统可以分配不同的读写权限便于管理 当指令和数据分离的时候，CPU缓存的命中率会更高 当指令和数据分离的时候，多个进程可以共享同一份指令，节省开销 ELF Header 是ELF文件最开头的一个结构体。它包含了描述整个文件的基本属性。因为ELF文件在各个平台下都通用，为了对每个成员的大小做出明确的规定以便保持兼容性。ELF使用typedef定义了一套自己的变量体系类似Elf32_Addr这种。下面简单列出文件头中的关键信息： ELF魔数，文件机器字节长度，数据存储方式，版本，运行平台， ABI版本，ELF重定位类型，硬件平台，入口地址（OS加载的虚拟地址，可重定位目标文件该值为0），程序头入口和长度， Section Header table的位置（以偏移量的方式）和长度及段的数量 魔数：当年的UNIX是在PDP小型机器上开发的，而当时的系统加载可执行文件直接从第一个字节开始运行，人们一般将第一条指令设置为跳转指令，这个魔数就是当时的JMP指令，为了兼容性被保留下来。 Section Header table 段表描述了ELF的各个段segment的信息比如段名，段长度，段偏移以及段的读写权限等。 实现上，一般会采取一个结构体数组来表示段表。 段类型： 很多类型比如.data,.text或者.rel,.string等 段标志位：表示该段在进程内虚拟地址空间中的属性 Relocation Table 目标文件中代码段和数据段那些对绝对地址的引用，需要在链接的时候重定位。每一个需要重定位的位置，最后都会有一个相应的重定位表比如.rel.txt,.rel.data等。 Sections .data: 保存初始化的全局变量和局部静态变量 .bss: 保存未初始化的全局变量和局部静态变量 .data: 保存代码段，等等 整个ELF文件有很多段比如字符串段，调试信息段strip等。包括在不同的平台标准上ELF格式都不同，这里不展开说了。 链接器 链接的本质就是要把多个不同的目标文件之间相互“粘”在一起——实际上就是目标文件之间地址的引用，及对函数和变量的地址的引用。 符号 在链接过程中，每一个ELF目标文件都会有一个相应的符号表，这个符号表对应ELF中的一个段.symtab，这个表里记录了目标文件所用到的所有符号，每个定义的符号有一个符号值，对于变量和函数来说该值就是其地址。 ELF的符号可以大致分为： 定义在目标文件中的全局符号 在目标文件内中引用的全局符号，又称为外部符号 段名 局部符号 链接器在生成可执行文件的时候，自行定义的特殊符号比如程序起始地址__executable_start 其中最重要的就是全局符号，因为其他的符号只是在目标文件中可见，而全局符号的作用域是跨文件的。 UNIX系统通过符号修饰和函数签名机制防止不同目标文件中的符号名称冲突。 (强/弱符号)(定义/引用) 编译器默认函数和初始化了的全局变量为强符号，未初始化的全局变量为弱符号。强符号和弱符号都是针对定义来说的，不是针对符号的引用。 不同的目标文件中不允许有同名的强符号 强符号可以屏蔽弱符号 而当外部变量的符号引用在目标文件被链接成为可执行文件时，如果是强引用，如果定义不存在则报错，而弱引用不会报错。强/弱引用一般用于库文件的链接过程。 静态链接 链接器一般都采用Two-pass Linking的方式： 空间与地址分配： 扫描所有的输入文件，获得它们各个段的长度，属性和位置，并将输入目标文件中的符号表中的所有符号定义和符号引用收集起来，统一放到一个全局符号表。 符号解析与重定位： 读取输入文件中段的数据，重定位信息；进行符号解析与重定位，调整代码中的地址。 各个段中的符号地址 代码中的地址引用 空间与地址分配 链接器能够获得所有输入目标文件的段长度，并且将它们合并，计算出输出文件中各个段合并后的长度和位置，并建立映射关系。 符号解析与重定位 这里有两部分，符号的地址和代码中的地址。其中链接器在完成地址和空间分配之后就可以确定所有符号的虚拟地址了，而链接器就可以根据符号的地址(通过查找由所有输入目标文件的符号表组成的全局符号表)对每个需要重定位的指令——即会用到外部符号的指令进行地址修正。 重定位表 链接器通过ELF文件中的重定位表来完成指令中地址的调整。 ABI 指的是和二进制兼容性有关的内容： 内置类型的大小和在存储器中的放置方式（大端，小端，对齐方式等） 组合类型（结构体，数组等）的存储方式和内存分布 外部符号与用户定义的符号之间的命名方式和解析方式 函数调用方式，比如参数入栈顺序，返回值如何保存等 堆栈的分布方式，比如参数和局部变量在堆栈中的位置，参数传递方式等 寄存器使用约定 静态链接库 静态链接库实际上就是一组目标文件的集合。即很多目标文件经过压缩打包之后的一个文件。 装载虚拟地址空间 首先32位CPU指的是CPU的数据线是32位的，但是其地址线不一定只有32位，PAE地址扩展方式修改了页映射的方式使得可以访问到更多的物理内存。而操作系统提供一个窗口映射的方式，将这些额外的内存映射到进程地址空间中。应用程序可以根据需要来申请和映射，比如Linux中的mmap系统调用。 关于现代操作系统的虚拟内存管理机制这里不展开介绍。 内核装载ELF可执行文件 一共有如下四个步骤： 进程创建 第一步是创建一个独立的虚拟地址空间。 创建虚拟空间实际上并不是创建空间而是创建映射函数所需要的相应的数据结构。在i386的Linux下，创建虚拟地址空间实际上就是分配一个页目录就可以了，甚至不设置页映射关系——这些等到后面程序发生缺页中断的时候再进行设置（当程序发生了页错误，操作系统将从物理内存中分配一个物理页，然后将该“缺页”从磁盘中读取到内存中，在设置缺页和物理页框的映射关系）。 这一步本质上就是完成虚拟空间到物理内存的映射关系。 完成ELF和进程的映射 第二步是读取可执行文件头，并且建立虚拟空间与可执行文件的映射关系。 很明显，这种映射关系是保存在操作系统中的一个数据结构（类似页目录）。Linux中将进程虚拟空间中的一个段叫做虚拟内存区域（VMA，Virtual Memory Area）。操作系统在内部保存这种VMA结构，就是因为当程序发生段错误的时候，可以通过查找这样一个数据结构来定位错误页在可执行文件中的位置。 运行 第三步是将CPU的指令寄存器设置成可执行文件的入口地址，启动运行。 操作系统进行内核堆栈和用户堆栈的切换，CPU运行权限的切换，然后设置CPU的指令寄存器并将控制权交给进程。 缺页中断 在上述步骤都完成之后，其实可执行文件的真正指令和数据都没有被装载进内存中。操作系统只是通过可执行文件头部的信息建立起来可执行文件和进程虚存之间的映射关系而已。 当发生一次缺页中断的时候，操作系统将查询这个数据结构，然后找到空页面所在的VMA ，计算出相应的页面在可执行文件中的偏移，然后在物理内存中分配一个物理页面，将进程中该虚拟页与物理页之间建立映射关系，完成真正的装载。 进程虚拟地址空间分布ELF文件链接视图和执行视图 操作系统装载ELF可执行文件的时候是以段segment为单位的，一般只关心跟装载有关的问题，最主要的是段的权限(可读，可写，可执行)。ELF文件中，段的权限往往只有为数不多的几种组合，基本上是三种： 以代码段为代表的权限为可读可执行的段 以数据段和BSS段为代表的权限为可读可写的段 以只读数据段为代表的权限为只读的段 一般对于相同权限的段，把它们合并在一起作为一个段进行映射——成为segment。多个sections组合成为segment，装载的时候一个segment在进程虚拟空间中只有一个对应的VMA，这样可以明显的减少内部碎片，从而节省了内存空间。 所以对于系统来讲，section是链接视图，而segment是执行视图。 在操作系统装载的时候，VMA除了用来映射可执行文件中的各个segment以外，事实上进程虚拟空间中的堆栈也是以VMA的形式存在的。所以总结一下，操作系统通过给进程空间划分出一个个VMA来管理进程的虚拟空间，基本原则就是相同权限属性的，有相同映像文件的映射成一个VMA，一个进程基本上可以分为如下几种VMA区域： 代码VMA，权限只读、可执行；有映像文件 数据VMA，权限可读写，可执行；有映像文件 堆VMA，权限可读写，可执行；无映像文件，匿名，可向上扩展 栈VMA，权限可读写，不可执行；无映像文件，匿名，可向下扩展 段地址对齐 因为装载过程是通过虚拟内存的页映射机制完成的。假设页大小默认为4096Bytes，所以如果要将一段物理内存和进程虚拟地址空间之间建立映射关系，这段内存空间的长度必须是4K的整数倍，并且这段空间在物理内存和进程虚拟地址空间中的起始地址必须是4096的整数倍。 系统为了防止碎片化，也会采取一些优化的映射方案，这里不深入了。 动态链接 静态链接有空间浪费和更新困难两个问题。 共享文件在内存中只存在一份，这样不仅仅节省内存，还增加CPU缓存的命中率。ELF动态链接文件称为.so共享对象文件，而Windows动态链接库称为.dll文件。 当程序被装载的时候，系统的动态链接器会将程序所需要的所有动态链接库装载到进程的地址空间，并且将程序中所有未决议的符号绑定到相应的动态链接库中，并进行重定位工作。也就是说动态链接器把链接这个过程从本来的程序装载前被推迟到装载的时候。这样的话动态链接与静态链接相比，性能损失大约在5%以下。这点损失换取空间上的节省和程序构建和升级时的灵活性，是想当值得的。 地址无关代码 由性质可以知道共享对象在编译的时候不能假设自己在进程虚拟地址空间中的位置。而可执行文件基本可以确定自己在虚拟地址空间中的起始位置。这里注意动态链接的模块概念：可执行文件模块和正常静态链接一样，而共享对象模块即动态链接库就不行。 那共享对象在被加载的时候，如何确定它在进程虚拟地址空间中的位置？ 这里提出一个问题：如果直接将目标文件推迟到装载的时候再链接可以吗？ 答案是不行。动态链接模块被装载映射到虚拟空间之后，指令部分是在多个进程中共享的，由于装载的时候重定位的方法需要修改指令（会影响代码段中的绝对地址引用），所以没有办法做到同一份指令被多个进程共享。 所以最终的解决办法就是：将共享的指令部分中那些需要被修改的部分分离出来，跟数据部分放在一起，这样指令部分就可以保持不变，而数据部分可以在每个进程中拥有一份副本——所谓地址无关代码(PIC, Pisition-independent Code)技术。 代码段地址无关代码 这里把共享对象模块中的地址引用按照是否跨模块分为两类：模块内部引用和模块外部引用；按照不同的引用方式有可以分为指令引用和数据访问。 模块内部的函数调用，跳转等 模块内部的数据访问，比如模块中定义的全局变量，静态变量 模块外部的函数调用，跳转等 模块外部的数据访问，比如模块中定义的全局变量，静态变量 这里提一下模块间，因为这些全局变量的地址是跟模块装载地址有关的。ELF的做法就是在数据段中建立一个指向这些变量的指针数组，也被称为全局偏离表(Global Offset Table GOT)，当代码需要引用该全局变量的时候，可以通过GOT中相对应的项间接引用。 链接器在装载模块的时候会查找每个变量所在的地址，然后填充GOT中的各个项，以确保每个指针所指向的地址正确。GOT在数据段所以可被修改。总结一下： 指令跳转，调用 数据访问 模块内部 相对跳转和调用 相对地址访问 模块外部 间接跳转和调用GOT 间接访问GOT 共享模块的全局变量问题 这里需要注意，如果一个模块引用了一个定义在共享对象的全局变量的时候。编译器无法判断该global是在同一个模块的其他目标文件中，还是定义在另一个共享对象中。 解决办法是所有的全局变量都通过GOT访问。 数据段地址无关代码 数据段中也会出现绝对地址引用的情况： 123&gt; static int a;&gt; static int *p = &amp;a;&gt; &gt; 这里的指针p就是一个绝对地址。一般来说，如果发现数据段中有绝对地址引用，编译器和链接器会产生一个重定位表。 对于可执行文件来说，默认情况下，如果可执行文件是动态链接的，那么编译器会使用PIC的方法来产生可执行文件的代码段部分，以便于不同的进程能够共享代码段，节省内存。所以一般动态链接的可执行文件中会有.got段。 动态链接过程 动态链接情况下，可执行文件的装载与静态链接情况基本一样。首先操作系统会读取可执行文件的头部，检查文件的合法性，然后文件头中读取每个“Segment”的虚拟地址，文件地址和属性，并将它们映射到进程虚拟空间的相应位置，这些步骤跟前面的静态链接情况下的装载基本无异。在静态链接情况下，操作系统接着就可以把控制权转交给可执行文件的入口地址，然后程序开始执行，一切很顺利。 但是在动态链接下，操作系统还不能再装载完可执行文件之后就把控制权交给可执行文件，因为我们知道可执行文件依赖于很多共享对象，这时候可执行文件里对于很多外部符号的引用还处于无效地址的状态，即还没有跟相应的共享对象中的实际位置链接起来。所以在映射完可执行文件之后，操作系统会其中一个动态链接器。 动态链接分为三步：启动动态链接器本身，然后装载所有需要的共享对象，最后是重定位和初始化。 共享库 因为动态链接的诸多优点，操作系统中一般有很多共享对象——按照合理的组织和使用方式构建起来的共享库。共享库的更新会影响ABI的使用。 运行库 经过前面的介绍，基本上编译系统的概念都介绍完了。下面的部分涉及操作系统接口，也只是简单的介绍一下。 操作系统装载程序之后，首先运行的代码并不是main的第一行，而是某些别的代码，这些代码负责准备好main函数执行所需要的环境，并且负责调用main函数，这时候才可以申请内存，使用系统调用，触发异常，访问I/O。在函数返回之后会记录main的返回值，调用atexit注册的函数，然后结束进程。 运行这些代码的函数成为入口函数或者入口点。这些都是运行库的一部分。个人理解运行库的概念就是操作系统和应用层的接口，区别于系统调用，比如Glibc那样。 常用二进制工具(基于LLVM) 命令 说明 llvm-size 查看ELF文件的各个段的大小 llvm-readelf -h 查看ELF Header(部分) llvm-readelf -S 查看ELF Header(全部) llvm-objdump -s 将所有ELF段以十六进制的方式打印 llvm-objdump -d 将所有指令段反汇编 字节寻址,小端 llvm-nm 查看ELF文件的符号表 c++filt 解析函数签名 ld a.o b.o -e main -o ab 直接使用链接器生成可执行文件ab（将main函数作为程序入口） llvm-objdump -r 查看目标文件的重定位表 ar -t libc.a 查看静态链接库包含了那些文件 clang -fPIC -shared lib.so lib.c 编译一个共享对象文件]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
        <tag>Compiler</tag>
        <tag>Linker</tag>
        <tag>Loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC-RISCV交叉编译工具链]]></title>
    <url>%2F2020%2F02%2F16%2FGcc-RISCV%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91%E5%B7%A5%E5%85%B7%E9%93%BE%2F</url>
    <content type="text"><![CDATA[Absrtact 旨在x86平台上编译RISCV架构的可执行文件。 RISCV作为一款极具使命感的指令集，其软件栈也是非常完整的。交叉编译环境可以在这里下载。 交叉编译工具链包括: GCC编译器 C运行库 Glibc : gnu旗下的库，作为linux的标准库和内核打交道 Newlib： 在嵌入式中使用广泛 Buntils二进制套件 GDB调试器 不同版本的工具链 Version Note Riscv-unknown-linux-gnu-gcc 132位架构的2Linux版本 Riscv-unknown-elf-gcc 32位架构的非Linux版本 每个版本都有32位架构和64位架构，这里的位数和运行本机的字长无关，指的是没有通过-march=和-mabi=选项指定RISCV架构的位宽 Linux版本指的是该工具链使用Linux系统中运行的Glibc作为C运行库——另外的个版本则使用Newlibc库 交叉编译选项-march=​ 由于$RISCV$为模块化指令，该选项支持不同的模块化指令集组合,关于$RISCV$模块见后面的介绍: rv32i[m][a][f[d]][c] rv32g[c] rv64i[m][a][f[d]][c] rv64g[c] -mabi=​ 该选项选定了目标平台所支持的ABI函数调用: ilp32，ilp32f，ilp32d 32位架构(int-32位 long-32位 long long-64位) lp64，lp64f，lp64d 64位架构(int-32位 long-64位) 后缀 suffix Note — 使用浮点类型操作直接使用RISCV浮点指令进行支持，但是当浮点数作为函数参数进行传递时，无论是单精度还是双精度均需要存储器中的堆栈进行传递 -f 使用浮点类型操作直接使用RISCV浮点指令进行支持，但是当浮点数作为函数参数进行传递时，单精度通过寄存拿起传递，双精度通过内存堆栈传递 -d 使用浮点类型操作直接使用RISCV浮点指令进行支持，但是当浮点数作为函数参数进行传递时，单/双精度均可通过寄存器传递 只有-march=支持浮点扩展，(-mabi=)才允许加上f/d后缀以支持浮点运算。 RISCV汇编语言简介 总结 目前交叉编译平台主要有两部分: riscv32-unknown-elf-gcc平台编译生成$RISCV$可执行文件，而qemu-riscv32平台运行RISCV可执行文件。 qemu是一款很强大的虚拟机，分为系统模式和用户模式，用户模式运行可执行文件，而系统模式模拟特定指令集从而运行操作系统镜像文件。]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>Compiler</tag>
        <tag>RISCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从syscall的角度理解操作系统]]></title>
    <url>%2F2019%2F06%2F25%2F%E4%BB%8Esyscall%E7%9A%84%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Abstract 操作系统控制硬件资源并完成底层抽象。 UNIX和C的发展一脉相承。20世纪80年代以来，针对UNIX的各种标准化工作对其实现提供了具体的限制以此来完善系统不同实现之间的可移植性——ISO-C，IEEE-POSIX以及Single UNIX Specification等等。 这些标准本质上是应用程序和操作系统接口的子集。一个操作系统的具体实现除了内核之外，最重要的就是对API的封装。UNIX一般通过系统调用和运行库的方式来完成应用程序接口，比如GNU为Linux开发的Gblic就支持ISO-C和IEEE-POSIX等核心标准。 个人觉得从系统编程和内存的角度去理解文件系统和进程/线程等OS核心概念会比较有趣。 文件系统 文件系统是一种持久性存储的系统抽象。并涉及到磁盘空间和内存空间的IO操作，比较难理解： 文件描述符表，打开文件表，i节点是文件存储的本质，而文件长度，文件偏移量，文件所占磁盘空间，文件用户权限是文件的重要属性。可以从dup，lseek，stat/chmod等函数理解 理解内核获取文件的过程是最核心的。这涉及到内核页高速缓存，用户区间缓冲区，标准IO缓冲区等核心概念。可以从read/write，fgets/fputs，sync/flush函数理解 从用户时间和CPU时间理解标准IO函数和read/write等系统调用。系统调用的开销要大于函数调用。而这一切都取决于双方缓冲区的选择 进程 进程是独立功能的程序在数据集合上的一次动态执行过程。 准备 就绪 阻塞 执行 结束 内核为每个进程维护一个进程控制块，从fork/exit/wait等函数可以理解这些状态。另外fork/exec区分了父子进程在创建前后所共享的资源： 代码段（但是子进程获得父进程数据空间，堆栈空间的副本） 打开的文件描述符 实际ID，有效ID，设置ID 存储映像 线程 每个线程都包含又表示执行环境所必需的信息，其中包括进程中表示线程的线程ID，一组寄存器值，栈，调度优先级和策略，信号屏蔽字，errno变量以及线程私有数据。一个进程的的所有信息对该进程的所有线程都是共享的，包括可执行程序的代码，程序的全局内存和堆内存，栈以及文件描述符。 进程是资源分配单位 线程是CPU调度单位 多线程切换因为相同那那个的地址空间——页表，因此切换更快。]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>UNIX</tag>
        <tag>Syscall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mit6.828(Fall 2018) Lab2]]></title>
    <url>%2F2018%2F11%2F22%2FMit6-828-Fall-2018-Lab2%2F</url>
    <content type="text"><![CDATA[Lab2Before Lab Lab2的主要内容:Physical Page Management,Virtual Memroy,Kernel Address Space;代码实现JOS中的内存分页管理功能，有页面管理和页表管理两部分。和理论相比，代码实现需要考虑的细节真是太多。实验最终的目的是通过几个检测函数: Lab1完成时整个JOS内存布局如下图: 切换合并Git分支的时候可能会出现冲突，需要手动注释掉Lab1中的一些测试代码来解决，这里不再赘述。 memlayout.h和pmap.h 掌握这两个文件中的函数是完成Lab2必不可少的条件，在此进行总结。 pmap.hLab2中需要重点关注的对象有三个:物理内存，虚拟内存，空闲链表struct PageInfo。该头文件中的函数实现了三者之间的相互转化。 另外还有几个外部变量也需要重点关注一下: bootstack 内核栈 pages 所有物理内存按照4KB划分的对应映射数组 npage 数组元素个数 kern_pgdir 页目录注意pages不是空闲链表，仅仅只是一个数组而已。而pages数组索引就是所有页式物理内存的索引。所以struct PageInfo *pp和物理内存关系很紧密：(pp-pages)*4KB就是该数组元素对应的物理页面page的物理地址，这也是page2pa函数的原型。 memlayout.h 介绍了JOS虚拟内存的详细布局，定义了所有需要使用的宏。在Lab2中，我们需要完成的是内核部分虚拟地址到物理的映射。所以重点关注的是UTOP之上的布局.当然需要注意的细节就很多了，比如大小，权限，每一部分内存的作用等。 上图只是一个简化图，结合源码看会好很多，比如一些和大小有关的宏定义: 1234#define PGSIZE 4096 // bytes mapped by a page#define KSTKSIZE (8*PGSIZE) // size of a kernel stack#define PTSIZE (PGSIZE*NPTENTRIES) // bytes mapped by a page directory entry#define NPTENTRIES 1024 // page table entries per page table 其中阴影部分指的是page_init()函数之前已经初始化好的。这是因为在page_init()函数之前分页机制还没有建立好，所以只能用字节分配的方法分配物理内存。这些阴影部分的物理内存都是boot_alloc(uing32_t n)函数分配的；而page_init()函数之后，所有的物理内存分配都是以页Page为单位，所以字节分配函数boot_alloc()也被禁用了。 总结 我觉得整个Lab2就是在实现两种映射：物理内存到空闲链表的映射和虚拟内存到物理内存的映射。而上述的两个头文件基本讲清楚了映射需要实现的步骤和原理，应该反复阅读。初此之外还应该对C语言的强转，指针，位运算有一个很深的了解，最好先看一下TCPL。 Physical Page Management 理论课很大的一部分缺失就是没有对物理内存布局进行讲解。而没有物理内存的基础，映射（Mapping）根本无从谈起。页面管理分析如下:从代码角度看，Lab2接上Lab1中kern/entry.S跳转到kern/init.c中的i386_init()开始执行。可以发现mem_init()函数，整个Lab2就是完善这个内存函数的过程。而第一部分物理内存就是完成将物理内存映射到空闲链表上。PartOne需要完成物理内存的管理，并实现物理内存的布局。这里的布局指的是对空闲链表的管理。所以我们首先要创建空闲链表，然后用空闲链表对这一整块物理内存进行管理，当然管理的单位是Page（4K）。基本上需要实现的代码都在pmap.c中。我们用Taglist统筹一下该文件中所有的函数和宏定义: boot_alloc 彼时mem_init()函数中还只有一个函数————i386_detect_memory()。用来检测物理内存的硬件状态及其参数，其中有几个比较重要的变量:1234npages: 未分配npages_basemem: 160kern_pgdir: 未分配basemem: 640KB 其中basemem=640K是因为在inc/memlayout.h中定义过一个宏:#define IOPHYSMEM 0xA0000。在Lab1的内存布局中有详细的分布，在这个宏定义的地址往上是 实模式下IDT和第一部分bootsector。所以将宏定义以下到0x00000000的内存称为base_mem。而这部分需要被映射到空闲链表中，所以按照页式单位可以映射640K/4K=160个pages。接下来就是实现代码。因为代码太多不打算贴出来，主要是做Lab的思路并分享一些完善内存布局过程中画的草稿。从mem_init()的进度来看，首先需要实现boot_alloc()函数，然后用该函数直接分配物理内存给kern_pgdir和pages两个数据结构。而boot_alloc中值得一提就是extern char end[]和对齐函数ROUNDUP(a, n)。在Lab1完成之后，我们将内核放到0x10000000这个位置直到end结束，所以end是链接器做链接时内核加载结束的地址。而ROUNDUP(a, n)的功能是向上对齐。因为我们的操作都是4KB对齐的，所以需要在end后面进行对齐操作。详细见Lab1的内存布局。最后函数返回的是已分配内存的虚拟首地址。指导书中推荐使用断言assert进行调试的方法。不过我一般使用输出调试cprintf+return。当分配好kern_pgdir和pages之后，我们使用输出调试看一下这两个数据结构的虚拟地址:1234567void boot_alloc() &#123; cprintf(&quot;before allocating nextfree is %x\n&quot;, nextfree); /* address allocator */ cprintf(&quot;after allocating nextfree is %x\n&quot;, nextfree);&#125; 看一下输出结果: 然后就是实现page_init()函数。此时我们已经建立了一个和全部物理内存相对应的数组pages。这为接下来空闲链表的实现奠定了基础:page_init()函数就是按照Hints中提示的物理内存的基本布局，找到那些空闲的物理内存并将其对应的pages数组元素链接起来形成一个链表。可能不好理解，直接上图: 这个功能是由下面简单的几句C语言实现的：1234567Part of the code: for (i = 1; i &lt; npages_basemem; i++) &#123; pages[i].pp_ref = 0; pages[i].pp_link = page_free_list; page_free_list = &amp;pages[i]; &#125; page_init函数实现了空闲链表。至此内存的布局已经很清楚了： page_alloc page_alloc函数实现物理内存的页式分配————分配一页空闲的物理内存。根据上面的思路:pages数组就是全部物理内存的映射，而page_free_list是空闲物理内存的映射所以是部分pages元素链成的。所以我们实际上可以通过page_free_list指针来确定具体的物理地址:(page_free_list-pages)*4K。实现很简单，当中需要注意的细节初始化函数memset(void *v, int c, size_t n)中需要的地址是虚拟地址。这里先参考一下kern_pgdir的实现和初始化。 所以在实现中需要将page_free_list指向的pages元素映射到具体的物理地址page2pa, 然后将物理地址转化为虚拟地址PADDR并返回。 细节 至此物理映射到空闲链表的过程已经实现。boot_alloc和page_alloc最终返回的都是虚拟地址。还有一些宏定义和函数比如PGNUM(la)，memset(void *v, int c, size_t n)的参数也是虚拟地址。在Lab2中一个核心问题就是区分物理地址还是虚拟地址。因为mmu的缘故，访问内存的时候会进行一次线性地址到物理地址的转换。所不能直接使用物理地址。我们索性所有自定义用到地址的地方都使用虚拟地址，如果需要物理地址再使用PADDR(la)转化。 Virtual MemoryQuestion 首先区分逻辑地址，线性地址和物理地址的概念。Lab2屏蔽了逻辑地址到线性地址的转化，也就是GDT段式存储管理。直接从线性地址开始。指导书中重点讲解了虚拟内存，物理内存和指针这几个概念。觉得有一些意思，就把翻译贴上了: 另外，在之后的Lab中会遇到很多一个物理页面同时被映射到好几块虚拟内存中的情况。JOS使用struct PageInfo-&gt;pp_ref来管理页目录对页表页的引用的数量。见下面代码:1234mystery_t x;char* value = return_a_pointer();*value = 10;x = (mystery_t) value; 根据上面的分析，指针value是虚拟地址。而对value进行强转并赋值的只能是虚拟地址了。 pgdir_walk 在实现下面的代码之前，默认熟悉inc/mmu.h中的所有内容。该函数的作用很关键。给定一个虚拟地址，pgdir_walk函数返回一个指向该地址对应页表项的指针。而这个函数主要是为完成一部分虚拟地址到一部分物理地址的映射函数boot_map_region做准备的。所以只需要定位到页表项就可以，而不需要加上后12位偏移量。JOS的页目录（表）项PDE&amp;PTE的格式见下: 该函数的分析如下:12345678910111213141516171819pte_t *pgdir_walk(pde_t *pgdir, const void *va, int create)&#123; uintptr_t ptIndex = PTX(va); //PTX取出页表项的偏移量 struct PageInfo * newAlloc; //空闲链表指针 if(!(pgdir[PDX(va)] &amp; PTE_P)) &#123; //&amp;位运算是取出PTE_P这一位，看页表是否存在 if(create) &#123; if((newAlloc = page_alloc(1)) == NULL) return NULL; newAlloc-&gt;pp_ref++; // |位运算是合并位； 【20】+【12】分别为页目录项（注意不是页表项）20位的地址，后12位的标志位 pgdir[PDX(va)] = page2pa(newAlloc) | PTE_P | PTE_U | PTE_W; &#125;else &#123; return NULL; &#125; &#125; pte_t * pdPtr = KADDR(PTE_ADDR(pgdir[PDX(va)])); //取出页目录项的前20位 return pdPtr + ptIndex; //具体的指向具体页表项的指针&#125; 其中对页表项进行重新映射是关键的操作，便于理解还可以先取出前20位地址然后再加上标志位:12345678910111213... if(create) &#123; if((newAlloc = page_alloc(1)) == NULL) return NULL; newAlloc-&gt;pp_ref++; pgdir[PDX(va)] = page2pa(newAlloc); test = KADDR(pgdir[PDX(va)]); //先取出20位 pgdir[PDX(va)] = page2pa(newAlloc) | PTE_P | PTE_U | PTE_W; return test + ptIndex;//直接返回 &#125;else &#123; return NULL; &#125;... 分页机制原理见下图，而pgdir_walk函数完成的是前两部分的，最后的offset并不在其中: boot_map_region 接上pgdir_walk函数返回虚拟地址相对应的页表项指针。注意该函数的参数中有一项是权限perm是和PTE_P一起的，一旦映射就存在了。因为是页表项所以是4KB对齐的（因为屏蔽掉后12位）。我们使用页表项完成虚地址到物理地址的映射:1234567891011static voidboot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)&#123; int i; for(i=0; i&lt;size/PGSIZE; i++, va+=PGSIZE, pa+=PGSIZE) &#123; //4K 对齐 pte_t *pte = pgdir_walk(pgdir,(void*)va, 1); if(pte == NULL) panic(&quot;boot_map_region panic : out of memory!\n&quot;); *pte = pa | perm | PTE_P; //完成映射，并设置标志位来确定页表权限 &#125;&#125; 后面几个函数实现都很简单，不再赘述。至此，我们实现了内存页式管理的页表管理部分。 Kernel Address SpaceMapping 关于学习JOS对虚拟内存空间的整体布局。JOS是32位的操作系统，一共有4G的虚拟空间。以ULIM为分界线，界限以下为用户空间，以上为内核空间。其中从ULIM到KERNBASE部分作为内核的系统栈共4M空间。对于内存详细的布局可以从inc/memlayout.h中看到，这里的重点是因为内核和用户空间同时被映射到物理内存中，所以需要一种方式来避免两者之间相互读写。而且JOS和其他现代操作系统不同的是，整个OS只有一个页目录kern_pgdir（应该是每一个进程有一套完整的页表系统）。方法是权限位: 当一个程序试图访问一个虚拟地址的数据的时候，x86系统的保护机制运行为: 先检查短权限位DPL，不过和页式分配无关 再检查页目录相应表项的访问权限，如果不过也产生异常 最后检查二级页表相应页表的访问权限，不够就产生异常x86对权限的原则是不在页目录这一环节限制太多，让最终的访问控制在二级页表这一环节上在设置。实际上Intel手册上给出了一个页目录加页表的访问控制的组合控制效果: 实现mem_init函数的最后一部分内容，实现JOS的虚拟映射:首先我们将虚拟地址中[UPAGES, sizeof(pages)]部分映射到物理地址[pages, sizeof(pages)]上。然后我们将虚拟地址中[KSTACKTOP-KSTKSIZE, KSTACKTOP]部分映射到[bootstack, KSTKSIZE]上。最后将KERNBASE以上的虚拟地址映射到所有物理地址上。这里注意一下一个细节:123456void mem_init() &#123; ... // Permissions: kernel R, user R kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P; ... &#125; 这是在mem_init函数申请kern_pgdir之后就发生的映射，而这句代码本质上就是映射函数boot_map_region。目的很简单————完成kern_pgdir自身到UVPT的映射。我们不难明白，整个JOS只有一个页目录。Lab基本结束，这时候的JOS内存整体布局如下: Question 第一个问题上面刚回答过了，就是映射的细节问题。在映射的时候设置了PTE_U的用户才有读写权限。我们的UPAGES有4MB的空间，一个struct PageInfo大小8B。所以能管理的物理块为4MB/8*4KB = 2GB。管理内存的开销一共有物理映射pages,页目录,页表。如果第三个问题成立也就是说物理内存最大一共有2G的话，那pages大小一共有2G/4K*8=4M。而页目录kern_pgdir一共有4KB大小；相应的页表是4MB。一共有8MB+4KB。 entry.S这部分是在Lab1的时候遗留下来的问题，因为在系统刚启动的时候初始化过一个页目录entry_pgdir。关于细节可以参看kern/entrypgdir.c和kern/entry.S。这里介绍一些QEMU的新用法来进行调试（其实也在Lab2中是要求掌握的）: xp/Nx paddr 输出从paddr物理地址开始的N个字节的值 info register 输出当前寄存器的状态 info mem 输出当前完成映射的虚拟地址和对应权限 info pg 输出当前页表，页目录和页表项是分开的其实我们从Lab1的时候已经调试过，movl %eax,%cr0执行结束的时候打开分页机制。但是这次可以直接看到分页的结果和映射的结果还是很爽的，结合kern/entrypgdir.c来看一下便很容易回答最后一个问题: 1234567891011121314151617181920212223// The entry.S page directory maps the first 4MB of physical memory// starting at virtual address KERNBASE (that is, it maps virtual// addresses [KERNBASE, KERNBASE+4MB) to physical addresses [0, 4MB)).// We choose 4MB because that&apos;s how much we can map with one page// table and it&apos;s enough to get us through early boot. We also map// virtual addresses [0, 4MB) to physical addresses [0, 4MB); this// region is critical for a few instructions in entry.S and then we// never use it again.//// Page directories (and page tables), must start on a page boundary,// hence the &quot;__aligned__&quot; attribute. Also, because of restrictions// related to linking and static initializers, we use &quot;x + PTE_P&quot;// here, rather than the more standard &quot;x | PTE_P&quot;. Everywhere else// you should use &quot;|&quot; to combine flags.__attribute__((__aligned__(PGSIZE)))pde_t entry_pgdir[NPDENTRIES] = &#123; // Map VA&apos;s [0, 4MB) to PA&apos;s [0, 4MB) [0] = ((uintptr_t)entry_pgtable - KERNBASE) + PTE_P, // Map VA&apos;s [KERNBASE, KERNBASE+4MB) to PA&apos;s [0, 4MB) [KERNBASE&gt;&gt;PDXSHIFT] = ((uintptr_t)entry_pgtable - KERNBASE) + PTE_P + PTE_W&#125;; 不难发现其实在entry_pgdir中已经完成了0x00000000-0x00400000到0xf0000000-0xf0400000和到0x00000000-0x00400000的映射。而实现映射的方式也是直接讲地址写到页表项entry_pgdir中。通过调试，发现两次页目录的创建过程中，映射的地址都不一样: 至此Lab2完成，Challenge时间关系不做了。这是源代码.]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>MIT 6.828</tag>
        <tag>OS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mit6.828(Fall 2018) Shell]]></title>
    <url>%2F2018%2F11%2F17%2FMit6-828-Fall-2018-Shell%2F</url>
    <content type="text"><![CDATA[HW:ShellAbstract 6.828除了Lab之外还有针对小型操作系统XV-6的Readings和HomeWork。整个6.828也是围绕这两条线（Lab和HW）在走。Lab1让我适应了JOS的实验环境和调试技巧，但是Shell和System Calls才是真正属于操作系统的知识。关于XV-6的HomeWork都是建立在Readings基础之上的，本次HW需要实现一个小型的Shell，需要阅读的Readings有: XV-6.Chapter.0（重点资料） man fork, (3)exec，open， close TCPL 学习过程中最有意思的当属斩获新技能和新工具了:)介绍一个新的vim插件神器————Taglist。 简单来讲，它以目录树的形式列出当前文件中的symbol:函数名，宏定义和变量。帮助我们从宏观上快速了解源码。本身支持跳转。安装manual中讲的很清楚，就不再赘述了。下面是我的配置:1234567nnoremap &lt;silent&gt; &lt;F8&gt; :TlistToggle&lt;CR&gt;&lt;CR&gt; &quot;按f8开启Taglistlet Tlist_Show_One_File=0 let Tlist_Exit_OnlyWindow=1 let Tlist_Use_Left_Window=1 let Tlist_File_Fold_Auto_Close=1 add the above Configs to your ~/.vimrc 操作系统调用——System Calls 操作系统的工作总结起来就是抽象和资源分配。资源有内存分配，CPU调度等。而抽象指的就是系统调用。实验需要实现Shell中的命令，重定向和管道。每一个功能都是使用系统调用来实现的，所以将System Calls称为操作系统的接口一点都不过分。 Executing Simple Commandsfork fork系统调用创建一个子进程，对于父进程返回子进程的pid，对于子进程返回0。见下面代码:1234567891011int pid = fork(); //创建了子进程if(pid == 0) &#123; //父子进程都从这里开始执行，唯一区别就是pid不一样 printf(&quot;child: existing!\n&quot;); exit();&#125;else if(pid &gt; 0) &#123; printf(&quot;parent: %d&quot;, pid); wait(); //父进程等待 printf(&quot;child is done\n&quot;);&#125;else &#123; fprintf(stdeer, &quot;fork error!\n&quot;);&#125; 其中wait()系统调用返回一个退出的子进程。上面这段代码其实就是整个Shell执行指令的原理:Shell提示符由父进程提供，然后创建一个子进程执行真正的命令，而父进程则wait()直到子进程返回,然后父进程等待下一条命令。执行效果如下: 回到Shell中来，我们需要修改子进程中的代码，能够正确执行简单的命令。涉及到exec()函数族。 execexec提供了在一个进程中执行另一个进程的方法: 根据参数提供的文件路径和名称找到可执行文件，并执行。执行结束之后原调用进程的内容除进程号之外其他的全部被替换。通常和fork一起联合实现进程中执行程序。exec函数族是由6个以exec开头的函数构成的，这6个函数的用法根据名称的不同会有些微的区别: 查找可执行文件的方式 其中execlp，execvp在查找可执行文件的时候不用写文件的绝对路径，系统会自动根据环境变量“$PATH”查找。env命令可以列出系统中当前的$PATH。 参数传递方式 其中execlp,execl,execle这三个第五个字母是l的函数参数只能分别列出来————const char *argv...。而execv,execve,execvp这三个第五个字母是v的函数参数可以整体构造数组传递————char *const argv[]。所有的参数都应该以NULL结尾。 环境变量 其中execle和execle可以在使用指定的环境变量。通过在参数末尾加上char *const envp[]的方法。 总结见下图: exec函数族使用注意事项 因为exec函数经常调用失败，所以需要加上判断语句 最后参数一定用NULL结尾1234567int exec() &#123; int ret; if( fork() == 0 )&#123; if((ret = execlp(&quot;ls&quot;, &quot;ls&quot;, &quot;-al&quot;, NULL)) &lt; 0) //参数以NULL结束 fprintf(stderror, &quot;execlp error!\n&quot;); &#125;&#125; 实现命令 Shell代码分为两个部分:词法分析和命令执行；实验需要修改runcmd()函数代码，实现具体的EXEC。需要关注函数类型，参数两个细节。根据调试知道&#39; &#39;为EXEC，而execcmd结构体中argv[0]中存储的是命令的名称，所以我们使用execvp来实现，execvp函数的第一个参数是可执行文件的名称，往后的参数可以用数组表示，这样可以保证该命令的可变参数得到实现。代码如下: 12345678910111213141516case &apos; &apos;: ecmd = (struct execcmd*)cmd; if(ecmd-&gt;argv[0] == 0) _exit(0); int pid, ret; if ((pid = fork()) == 0) &#123; if((ret = execvp(ecmd-&gt;argv[0], ecmd-&gt;argv)) &lt; 0) &#123; fprintf(stderr, &quot;Bash: command not found:%s\n&quot;, ecmd-&gt;argv[0]); exit(-1); &#125; exit(0); &#125; else if (pid &gt; 0) &#123; wait(0); &#125; break; 注意因为是多线程编程，所以调试的时候会出现很多不可思议的现象。可以先将fork()部分注释掉，进入执行函数看一下现象，然后输出调试。执行效果如下: I/O Redirection文件描述符 文件描述符是很重要的概念，它使得重定向成为可能。File Descriptor是一个整数，常常把其指向的对象称为文件。本实验中需要了解open，creat，close，dup2等系统调用返回值就是一个文件描述符。我们需要做的就是将Shell本身的文件描述符指向其他的文件描述符，从而实现重定向。Shell保证在任何时候都有3个打开的文件描述符————0-标准输入,1-标准输出,2-错误输出。下面是会用到的几个系统调用: open(&quot;file_name&quot;, O_RDWR): 打开文件，打开成功返回值最小的文件描述符————标准输入0，打开失败返回-1 create(&quot;file_name&quot;, 0777): 创建文件，返回值同open close(fd): 释放一个文件描述符 dup2(oldfd, newfd): 将oldfd复制给newfd 重定向不需要考虑子进程的问题，但还是需要深入了解fork函数的机理，一旦fork，父进程拥有和子进程一模一样的文件描述符。而重定向需要考虑的是在子进程中将标准输入（输出）定向到其他文件即可。 &lt; 输入重定向较简单，一旦文件不存在直接报错:12345678910case &apos;&lt;&apos;: rcmd = (struct redircmd*)cmd; close(0);//关掉父进程的标准输入 if(open(rcmd-&gt;file, O_RDONLY) &lt; 0) &#123; fprintf(stderr, &quot;Bash: No such file or directory: %s\n&quot;, rcmd-&gt;file); //输入不存在直接报错 &#125;else &#123; //一旦open函数执行成功，它返回得文件描述符就是0，所以这时候该文件就变成了输入,定向成功 runcmd(rcmd-&gt;cmd); //这里就是执行EXEC部分，所以fork的时候标准输入也是关闭的（和父进程一样close） &#125; break; &gt; 输出重定向 如果文件不存在。创建新的文件时需要注意文件的权限。creat函数的参数0777权限为-rwx rwx rwx。关于umask的知识见这里。123456789101112131415case &apos;&gt;&apos;:rcmd = (struct redircmd*)cmd;int fd;if((fd = open(rcmd-&gt;file, O_RDWR)) &lt; 0) &#123; //fd为新打开文件的文件描述符 if((fd = creat(rcmd-&gt;file, 0777)) &lt; 0 ) &#123; fprintf(stderr, &quot;Bash: No such file or directory: %s\n&quot;, rcmd-&gt;file); &#125;else &#123; dup2(fd, 1); //将标准输出指向到新打开的文件fd上，所以输出就到了该文件上（实现了重定向） runcmd(rcmd-&gt;cmd); &#125;&#125;else &#123; dup2(fd, 1); runcmd(rcmd-&gt;cmd);&#125; break; 执行效果如下: Implement pipes 管道是一个小小的内和缓冲区，它以文件描述符对的形式提供给进程，从管道的一端写数据可以从管道的另一端读取。系统调用pipe将数组int p[2]初始化为管道的文件描述符。接下来做的无非就是重定向了。12345678910111213141516 case &apos;|&apos;:pcmd = (struct pipecmd*)cmd;int p[2];pipe(p); //管道初始化if(fork() == 0) &#123; dup2(p[0], 0); //将标准输入重定向到管道的输入p[0]上 close(p[0]); close(p[1]); runcmd(pcmd-&gt;right);&#125;else &#123; dup2(p[1], 1); //讲标注输出重定向奥管道额输出p[1]上 runcmd(pcmd-&gt;left); close(p[0]); close(p[1]);&#125;break; 执行效果如下: Make grade 6.828对于HW的测试是直接在主机上测试的，编译Shell文件:gcc Shell得到a.out。已知该文件t.sh:123456ls &gt; ycat &lt; y | sort | uniq | wc &gt; y1cat y1rm y1ls | sort | uniq | wcrm y 在主机上，执行./a.out &lt; t.sh与在主机Shell上执行source t.sh对比结果，如下: 本次实验的源代码在Github上。第一次接触Linux系统编程，很多零碎的知识和细节学起来很是吃力。不过在独立搞懂Shell的机制之后又觉得很爽，还是很期待之后的挑战:)]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>MIT 6.828</tag>
        <tag>OS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mit6.828(Fall 2018) Lab1]]></title>
    <url>%2F2018%2F11%2F05%2FMit6-828-Fall2018-Lab1%2F</url>
    <content type="text"><![CDATA[Lab1Before Lab Lab1一共有三部分:Bootstrap,BootLoader,Kernel;前两部分都是GDB调试为主，熟悉GDB的调试技巧和操作系统的启动流程。最后实现一小部分monitor中test_backtrace的功能。如果GDB调试出错，可能是因为调试器没有链接到操作系统上：123add add-auto-load-safe-path /Your Working Dir/.gdbinitline to your configuration file &quot;/root/.gdbinit&quot; PC BootstrapGetting Started with x86 assemblyExercise 1 JOS中使用AT&amp;T格式的汇编语言，在Lab0中介绍了相关资料。实验要求熟悉x86汇编和Inline汇编两种写法。 Simulating the x86 Lab1的工作目录: /boot目录包含和启动相关的文件。 /kern目录包含内核和监视器相关的文件。 /lib目录包含一些链接使用的库函数比如printf。 /inc目录包含头文件，申明了需要使用的数据结构。 /obj目录是make之后相应的反汇编代码，供调试使用。Lab1主要分析/obj/kern/kern.asm和obj/boot/boot.asm两个文件。这两个文件分别是/boot和/kern目录下的文件编译连接后的目标文件被反汇编而生成的。之所以这样做是因为反汇编之后可以看到每一条指令在内存中的绝对地址。这样调试的时候非常方便。至于实模式和保护模式下的地址转换在后续的实验中也会重点关注。 The PC’s Physical Address Space 最早的8086机器只有1Mb的寻址空间，后面的80x86系列机器为了向后兼容所以衍生出实模式和保护模式这两种概念，但是BIOS一直都存在于从0x00000000到0x00100000这1Mb的空间中。JOS的内存布局也是规定只有0x00000000到0x10000000这256MB大小的空间，但是默认地址线是32位的。这个很重要，因为后面实验对JOS进行虚拟内存分配的时候页框地址最大也只能是0x10000000，内核如何处理映射就是一个问题。具体布局见下图: The ROM BIOSExercise 2 这里介绍一下常用的GDB调试参数: si: 单步调试 info register: 查看当前各寄存器的值 x/Nx Addr: 查看内存地址Addr之后N字的内容 x/Ni Addr: 查看内存地址Addr之后的N条反汇编指令 x/Ni $eip: 查看CPU当前执行的下N条指令（其中$eip可以换成不同的寄存器，这里就不一一列举了）通过分析前面的JOS内存的布局，BIOS作为固件存在于0xf0000到0xfffff这64KB的空间上。注意启动为实模式，CPU的地址线寻址都是20位的。启动仿真器之后看到第一条代码停在了0xffff0的地址上，说明这是BIOS程序的入口。0xffff0到BIOS程序顶部0xfffff只有16字节的空间，需要更大的运行空间，因此第一条指令ljmp $0xf000,$0xe05b；也就是跳转到0xfe05b这个地址正式开始运行BIOS的程序。BIOS本身也是一个很复杂的系统，但是和OS关系不大。通过调试BIOS的代码我们知道了它的功能: 建立中断向量表及相应的中断例程 初始化部分硬件及自检(POST) 激活INT 19中断来加载启动盘第一扇区512字节的内容到内存(Linux)这里应该说明第一扇区的内容是/boot目录下的内容:boot.S和main.c,这两个文件最后被编译链接成为可执行目标文件(这里需要ELF的知识)。在Linux系统中，这个可执行目标文件大小就是512字节，正好放在启动盘的第一个sector中,被称为bootsect。而BIOS的主要工作之一就是将bootsect加载到内存中，执行完任务之后，BIOS跳转到bootsect的初始位置。至此BIOS将权限交给操作系统，OS继续完成剩下的启动过程。这里发现了一个小问题:就是在查看/obj/boot目录的时候，发现出现了boot.out和boot两个文件，如下: strip命令将ELF文件中的符号表信息等调试信息删掉，减少文件本身的大小。理论上讲bootsect最后应该被链接到启动盘kernel的第一个扇区上，换句话讲最后的操作系统启动盘只有一个。查看/obj/boot目录下生成的这个两个文件:boot.out的格式为可执行目标文件，boot是x86 boot sector的格式，这两个文件中一定有一个作为bootsect链接使用。见下图: 可是经过分析这两个文件大小都是8K,经过优化之后也要4K大小，和512Bytes相差太远。而且文件boot还不可以使用二进制工具分析。这个细节方面应该和链接关系很大，《程序员的自我修养》这本书是国内少有的讲链接装载的好书，有时间再拜读吧。 The Boot LoaderCode分析boot/boot.S 分析一下/boot/boot.S这个文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172##############1.申明部分###############.set PROT_MODE_CSEG, 0x8 .set PROT_MODE_DSEG, 0x10 .set CR0_PE_ON, 0x1 #################2.16位实模式部分##########.globl startstart: .code16 cli %禁止中断 cld xorw %ax,%ax %清零段寄存器 movw %ax,%ds movw %ax,%es movw %ax,%ss ###开启A20地址线##seta20.1: inb $0x64,%al % 将64号端口的内容读到%al寄存器中 testb $0x2,%al %检测%al的第二位是否为零（代表输入缓冲区是否为满，可以对端口继续读写） jnz seta20.1 %不为零则重复执行seta20.1 movb $0xd1,%al %将$0xd1写入%al寄存器 outb %al,$0x64 %将%al寄存器的值写入64号端口seta20.2: %同样的方式 inb $0x64,%al testb $0x2,%al jnz seta20.2 movb $0xdf,%al outb %al,$0x60 %两个端口读写 激活A20地址线###实模式————&gt;保护模式## lgdt gdtdesc %加载GDT movl %cr0, %eax orl $CR0_PE_ON, %eax %取出%CR0寄存器的第零位并置1 movl %eax, %cr0 %实模式向保护模式的转换 ljmp $PROT_MODE_CSEG, $protcseg ###########3.32位保护模式部分############# .code32protcseg: movw $PROT_MODE_DSEG, %ax movw %ax, %ds movw %ax, %es movw %ax, %fs movw %ax, %gs movw %ax, %ss movl $start, %esp call bootmainspin: %BUG Point！ jmp spin###########4.数据区################.p2align 2 gdt: SEG_NULL SEG(STA_X|STA_R, 0x0, 0xffffffff) SEG(STA_W, 0x0, 0xffffffff) gdtdesc: .word 0x17 .long gdt 申明部分两个宏定义是在保护模式下的段描述符的申明，对于保护模式后面还有介绍，这里权把它们看成是CS和DS段寄存器。实模式部分首先关掉了中断cli，因为接下来就要进行实模式下中断服务例程向保护模式下IDT中断描述符的交接。期间系统无法响应正常的中断服务。cld将标志位DF置零，DF和字符串操作相关;清零段寄存器。并打开了第21（A20）到第32根地址线，在没打开之前高于1MB的地址总是会“回滚”到0，这也是Linux检测保护模式和实模式的一个方法。接下来加载GDT，movl %eax, %cr0这句话是将系统控制寄存器%CR0的第0位（PE位）置一，意味着处理器工作方式变为保护模式。这里没有直接对%CR0进行操作，而是通过%eax来实现主要是为了不破坏寄存器的其他位，值得借鉴。最后ljmp $PROT_MODE_CSEG, $protcseg是跳转指令，需要注意的是现在已经是保护模式了，而在实模式下和保护模式下对于地址的转换方式已经从段寻址变成GDT寻址。这里只需要知道跳转到了protcseg这个地址。保护模式初始化了重要的段寄存器，然后跳转到boot/main.c/bootmain函数，开始将启动盘剩余的内核部分载入内存。注意在AT&amp;T格式的汇编语言中，操作数的字长是由操作符的最后一个字母决定的，后缀’b’,’w’,’l’分别表示字节（byte:8位），字（word:16位）和长字（long:32位）。数据区部分都是在保护模式下建立GDT全局描述符的时候相关的宏定义。 分析boot/main.c 分析一下boot/main.c这个文件: 123456#define SECTSIZE 512#define ELFHDR ((struct Elf *) 0x100000)void readsect(void*, uint32_t);void readseg(uint32_t, uint32_t, uint32_t);void bootmain(void); 先看这两个宏定义，SECTSIZE是磁盘一个sector的大小，一般读写操作都要求地址对齐，这个宏定义就会派上用场。ELFHDR是一个指向ELF文件结构体的指针，不得不说强转是C语言最有力的工具之一，由此可知0x100000便是内存载入的首地址。这个地址也是BIOS程序结束的地方，可见JOS对于内存的规划分配还是很精确的。 1234567891011121314voidreadseg(uint32_t pa, uint32_t count, uint32_t offset)&#123; //pa是加载地址 count是加载文件大小 offset是在内核文件中的偏移量 uint32_t end_pa; end_pa = pa + count; //结束地址 pa &amp;= ~(SECTSIZE - 1); //将加载地址与最小单位512对齐 offset = (offset / SECTSIZE) + 1; //计算加载部分在启动盘中的哪一个sector中，因为sector从1开始算起 while (pa &lt; end_pa) &#123; readsect((uint8_t*) pa, offset); pa += SECTSIZE; //这句话表明 最终分配的内存有可能是大于实际需要内存的，因为总是以512为最小分配单元分配的 offset++; &#125;&#125; readseg函数中的对齐，看下面这个sample函数: 123456789101112131415#include&lt;stdio.h&gt;int main() &#123; long SECSIZE = 0x200; long pa = 0x30301; long to = 0x10387; to &amp;= ~(SECSIZE - 1); pa &amp;= ~(SECSIZE - 1); printf(&quot;secsize is : %lx\n&quot;, SECSIZE); printf(&quot;pa is : %lx\n&quot;, pa); printf(&quot;to is : %lx\n&quot;, to);&#125; 之所以需要对齐，因为磁盘和内存之间读写如果按照规定的最小粒度进行，CPU的访问性能会提高。具体见IBM.alignment。上述函数的执行结果见下图: readsect函数都是一些端口操作。也没仔细研究Orz。下面主要看一下bootmain函数剩下的部分: 12345 ph = (struct Proghdr *) ((uint8_t *) ELFHDR + ELFHDR-&gt;e_phoff); eph = ph + ELFHDR-&gt;e_phnum; for (; ph &lt; eph; ph++) readseg(ph-&gt;p_pa, ph-&gt;p_memsz, ph-&gt;p_offset);((void (*)(void)) (ELFHDR-&gt;e_entry))(); 关于JOS对于ELF文件的申明见/inc/elf.h。一共有三个结构体，Elf代表文件头；Proghdr代表加载时候segment的信息；Secthdr代表运行时section的信息；在Lab0中，我们分析过对一个程序加载的时候是以segments为最小粒度的。所以我们重点关注Elf和Proghdr这两个结构体的细节。 e_phoff: segment表在整个程序中的偏移量 e_phnum: segment表项的个数 ph-&gt;p_pa: 该segment在内存中的加载地址 ph-&gt;p_memsz: 该segment的大小 ph-&gt;p_offset: 该segment相对于表起始地址的偏移量所以ph就是segment段表的开始地址。而eph就是segment段表的项数。这个循环是把所有的segments都加载到相对应的内存地址中。加载结束后，再次跳转((void (*)(void)) (ELFHDR-&gt;e_entry))(),通过调试反汇编代码，发现跳转的这个地址为call *0x10018,注意这里是一个指针，可以看到内核函数真正的入口在0x0010000c。所以正确的操作见下图: Exercise 3 在上面分析的过程基本上回答了所有的问题: %CR0标志位的改变意味着实模式切换到保护模式 call *0x10018是最后一条BootLoader执行的指令，movw $0x1234, 0x472是内核第一条指令，这条指令在0x0010000c这个入口地址。 通过读取ELF文件中关于加载segments的信息，因为main函数最开始加载了8个sectors的内容到内存中，这部分内容就是和ELF格式和细节信息有关系。 Loading the KernelExercise 4 重温C语言指针，实验中推荐TCPL。分析实验中给出的部分示例代码，体会指针的魅力: 1234c = (int *) ((char *) c + 1);*c = 500;printf(&quot;5: a[0] = %d, a[1] = %d, a[2] = %d, a[3] = %d\n&quot;,a[0], a[1], a[2], a[3]); 这段代码将c强转成为char类型的指针之后加一，然后赋值为500；问题就出现在char类型和int类型的指针大小是不一样的。int类型为4个字节，而char类型只有1个字节;所以这样势必会导致赋值的时候改变数组中原来的布局。已知a[1]原来的值400，16进制为0x190;a[2]的值原来为301，16进制为0x12D;500的16进制为0x1F4;一个地址单元为一个字节，为见下图: 可以看到读写操作是按照字节为最小单元，最后导致a[1]的值变成0x1F490也就是十进制的128144；而a[2]由于被抹掉以个字节，所以变成0x100也就是256。下图是最终的运行结果: Exercise 5 关于链接器和加载器，最经典的当然是这本loader and linker。这是中译本ll.Ch。不过我做实验的时候没有想明白他们为什么要在这里引入这两个复杂的概念；题目很简单，但是不知道LMA和VMA是和虚拟内存有关系还是和链接器，加载器有关系。后来用readelf -h kernel发现VMA就是虚拟地址，所以这里他们所谓的linking address和loading address只是实验中自行定义的字面意思加载的地址和执行的地址，和链接器加载器没有关系！！另外在Lab0中已经分析过加载时候的section是所有sections组合成的一个聚合节，这里不考虑链接时候的单个section的概念。这样的话，就可以明白实验讲解的思路————引入使用ELF中segments的概念来解释加载过程，而加载过程时候已经开启了分页机制，所以这时候用loading address和linking address来解释0xf0100000和0x00100000的区别。而实际上0xf0100000就是映射到0x00100000上，相关细节在Kernel部分会继续分析。readelf和objdump的操作见下图: 将链接地址改掉之后，第一条报错的应该是和链接地址直接相关的指令，跳转指令ljmp $PROT_MODE_CSEG, $protcseg; Exercise 6 前面分析过#define ELFHDR ((struct Elf *) 0x100000)所以我们可以知道，内核的装载地址(load address)就是0x00100000，而内核开始执行的地址应该是e_entry也就是0x0010000c。从BIOS到BootLoader的时候，内核还没有开始装载。所以0x00100000是空的。 The KernelUsing virtual memory to work around position dependence Lab1中的地址映射: 0x00000000————0x00400000映射到0x00000000————0x00400000；0xf0000000————0xf0400000映射到0x00000000————0x00400000;在实验过程中关注了一下地址: 在执行到kern/entry.S文件之前，所有的内存地址都是物理地址（书中代言为线性地址，但是线性地址=物理地址所以没有太大区分）。直到%CR0寄存器的PG标志位被置零。这时候分页机制才被激活。0x00100000和0xf0100000都映射到0x00100000，所有两个地址存储的数值是一样的。而在映射还没有建好之前是不一样的。 Exercise 7 %CR0寄存器PG位控制分页机制的实现。看到mov %eax, %cr0执行结束之后，索引地址变成了0xf0100010。地址映射不对，第一条错误的指令一定会是跳转指令jmp *%eax。具体的分页细节在Lab2中分析。实验操作见下图: Code分析kern/printf.c 下面分析一下kern/printf.c这个文件: 12345678910111213141516171819202122static void putch(int ch, int *cnt)&#123; cputchar(ch);//显示屏输出函数console *cnt++; //每进行一次显示屏输出，参数自加&#125;int vcprintf(const char *fmt, va_list ap)&#123; int cnt = 0; //cnt将自身指针传给putch(int, int*)，在函数里进行自加 vprintfmt((void*)putch, &amp;cnt, fmt, ap); //格式判断 return cnt; //返回最终输出的参数个数&#125;int cprintf(const char *fmt, ...)&#123; va_list ap; int cnt; va_start(ap, fmt); cnt = vcprintf(fmt, ap);//变参传递 va_end(ap); return cnt; //返回参数个数&#125; cprintf是主函数，这里用到了C语言的变参特性。变参在C库stdarg.h中定义至少要有一个固定的参数:fun(const char *fmt, ...)。主要有三个宏组成: va_list: 申明可变参数指针ap，依次指向省略号表示的可变参数 va_start(ap, lastFix): 初始化ap，开始指向第一个可变参数 va_arg(ap, type): 将ap指向下一个可变参数 va_end(ap): 清除ap指针，结束函数可以看到变参fmt和变参指针ap被一路传到vcprintf———&gt;vprintfmt。在vprintfmt中使用。该文件中重点关注两个函数: 在lib/printfmt.c中的函数: vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap) 在kern/console.c中的函数: cputchar(int c)经过观察之后就可以知道: vprintfmt函数判断字符串输出参数的类型并调用cputchar函数将相应的输出显示到显示屏上。在函数分析之前再介绍一个vim的新技能:搜索高亮:match Search /xxx/,可以对现在正在关注的关键字进行高亮显示，调试的时候很有用: 分析函数vprintfmt vprintfmt函数其实很简单，主体就是一个while循环:在遇到%之前直接输出，遇到%之后开始判断格式并输出。 分析函数cputchar 在vprintfmt函数中需要注意一个变量:ch = *(unsigned char *) fmt++。ch代表了当前ap指针指向的变参，也就是我们需要输出的内容。cputchar(ch)中的参数正好就是这个ch。我们使用Ctags跟踪这个ch参数经过的函数:putch(int ch, int *)————&gt;cputchar(int ch)————&gt;cons_putc(int ch)。现在基本上可以看清所有的控制台输出操作都是定义在console.c文件中的。我们直接分析一下cons_putc(int ch)这个函数: 123456static void cons_putc(int c)&#123; serial_putc(c); lpt_putc(c); cga_putc(c);&#125; 上三个子函数都涉及到的内联汇编inb()和outb()两个函数在inc/x86.h中有定义。其中serial_putc是串口输出，lpt_putc是并口输出，而cga_putc是显示屏输出，具体不细分析了:123for (i = 0; !(inb(0x378+1) &amp; 0x80) &amp;&amp; i &lt; 12800; i++) delay(); //判断数据缓冲区寄存器是否为空，为空则一直循环 outb(0x378+0, c); //将C参数代表的内容写到端口中 另外，在cga_putc(c)函数中，有一段代码:1234567if (crt_pos &gt;= CRT_SIZE) &#123; int i; memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t)); for (i = CRT_SIZE - CRT_COLS; i &lt; CRT_SIZE; i++) crt_buf[i] = 0x0700 | &apos; &apos;; crt_pos -= CRT_COLS; &#125; 我们知道cga_putc(c)函数是用于显示屏输出的函数，而查看这几个宏定义:1234static uint16_t crt_pos //光标#define CRT_ROWS 25 //显示屏行#define CRT_COLS 80 //显示屏列#define CRT_SIZE (CRT_ROWS * CRT_COLS) //显示屏面积 简单来讲就是如果输出满屏之后，需要页面向上滚动一行。 Formatted Printing to the ConsoleExercise 8 经过上面的分析之后，知道格式化输出是在kern/printfmt.c/vprintfmt()这个函数中。找到相应的位置修改就行。 Questions 这是Exercise.8后面的一些问题，当然很简单了:1.cputchar(int c) 2.一句话，就是满屏时候的处理方法 3.主要是变参指针ap和格式化变参fmt的指向问题，之前分析过4.将代码加到kern/monitor.c中，输出见下图。因为57616的十六进制就是ell。而0x0x00646c72在小端存储的机器上用char*表示就是rld\0。如果想要用大端存储的话，只要反过来就行0x726c6400。 5.根据变参的定义，如果fmt参数不够，那最终ap指针会指向一个未知内存区域。所以输出的数不一定。见下图: 6.关于变参的定义是在inc/stdarg.h中,我们看一下va_arg是如何一次一次取出变参的:1234#define va_arg(ap, type) __builtin_va_arg(ap, type) //Fall 2018#define va_arg(ap, type) \ (*(type *)((ap) += __va_size(type), (ap) - __va_size(type))) //Fall 2015 可以看到va_arg是通过地址往后增长来取出下一个变参的。而正常编译器是从右往左的顺序将参数入栈的（因为栈是从高地址向低地址延伸的）。如果这时候栈的顺序变了，那只需要将va_arg函数中的对地址的加法改为减法就行。 The StackExercise 9 关于栈的定义在kern/entry.S中。见下图: 因为栈是从高地址向低地址延伸的，所以mov $(bootstacktop) %esp将栈顶地址赋值给%esp寄存器。而在数据段中对栈大小的定义也很清楚了————KSTKSIZE是一个宏定义，大小为8x4KB=32KB。 Exercise 10 需要深入了解栈调用的机制，就需要了解stack pointer%esp和base pointer%ebp这两个寄存器的用法。我们通过调试test_backtrace()函数来深入了解。(实际上只要有函数调用就会有栈，但很明显test_backtrace不是第一个调用的函数。当然你也可以从第一个函数i386_init开始，这个时候%esp也刚刚完成初始化0xf0110000,感觉会更爽一些)。test_backtrace函数的调用发生在kern/init.c/i386_init()中，所以我们第一个断点设置在0xf01000de。从反汇编代码中可以看出，开始调用test_backtrace之前，还有两条指令:12movl $0x5, (%esp)call f0100040 &lt;test_backtrace&gt; 在还没有开始执行的时候，查看一下寄存器的状态info registers:%esp的值为0xf010ffe0，%ebp的值为0xf010fff8。然后开始执行第一句，将参数5movl到栈顶，注意这里不是压栈而是直接存进去的，所以栈指针%esp是不会移动的。但是这时候栈顶元素应该是0x5。我们可以通过info registers命令和x/8x $esp来分别验证，效果如下: 在看一下第二条指令call f0100040。call指令可以分成两条指令:push %eip和jmp 0xf0100040。所以看到push指令是正宗的压栈指令，这时候%esp寄存器的值是要-4的，而且递减满堆栈的顺序是先-4，再压栈。这次栈顶元素应该是下一条指令的地址0xf01000ea，而且%esp的值还得-4。我们可以通过info registers和x/8x $esp来分别验证: 第三条指令就正式进入到test_backtrace函数内部了。分析一下函数内部的调用代码:12345678910111213141516171819202122void test_backtrace(int x)&#123;f0100040: 55 push %ebpf0100041: 89 e5 mov %esp,%ebpf0100043: 53 push %ebxf0100044: 83 ec 14 sub $0x14,%espf0100047: 8b 5d 08 mov 0x8(%ebp),%ebx cprintf(&quot;entering test_backtrace %d\n&quot;, x);f010004a: 89 5c 24 04 mov %ebx,0x4(%esp)f010004e: c7 04 24 20 1a 10 f0 movl $0xf0101a20,(%esp)f0100055: e8 c1 09 00 00 call f0100a1b &lt;cprintf&gt; if (x &gt; 0)f010005a: 85 db test %ebx,%ebx f010005c: 7e 0d jle f010006b &lt;test_backtrace+0x2b&gt; test_backtrace(x-1);f010005e: 8d 43 ff lea -0x1(%ebx),%eaxf0100061: 89 04 24 mov %eax,(%esp)f0100064: e8 d7 ff ff ff call f0100040 &lt;test_backtrace&gt;f0100069: eb 1c jmp f0100087 &lt;test_backtrace+0x47&gt; else...&#125; 基本上所有被调用的函数开头都会有这两条指令:push %ebp;mov %esp, %ebp;实验指导书上也解释了%ebp寄存器的作用:On entry to a C function, the function’s prologue code normally saves the previous function’s base pointer by pushing it onto the stack, and then copies the current esp value into ebp for the duration of the function.每一个函数都有一个%ebp值，作为函数的栈帧，需要在每次调用新函数的时候压栈以保存上一个函数的返回地址。这个时候莫名其妙的压栈了一个寄存器%ebx。我们将%ebx全局高亮显示发现，后面紧接着会有mov 0x8(%ebp), %ebx。那0x8(%ebp)存储的到底是啥？不难想到就是参数5。然后%esp指针接着扩展当前函数的栈空间。关注一下第二次调用test_backtrace()，前一条指令mov %eax, (%esp)和第一次调用的时候完全一样，而%eax中存的也是参数5-1=4;当然调用指令call也需要一次压栈。总结一下，如果是从push %ebp开始算起是函数栈的开头的话，那我们每一个函数调用会花费4（push %ebp）+4(push %ebx)+20(sub $0x14,%esp)+4(call)一共是32Bytes字节的空间。所以整个栈的布局见下图: 当然在调用过程中还调用了cprintf()这个函数，不过20字节用来分配栈空间也够了。 Exercise 11经过上面的分析，栈的布局已经很清楚了。所以我们需要知道对于read_ebp()函数来说读出的是当前%ebp指针指向的地址，所以按照上面栈的布局:(%ebp)--&gt;上一个%ebp,0x4（%ebp）--&gt;%eip,0x8(%ebp)--&gt;参数1…当然这里的参数比5个少。下面就是考验C语言的时刻，一定要注意格式:1234567891011121314151617181920212223intmon_backtrace(int argc, char **argv, struct Trapframe *tf)&#123; // Your code here. /* parameter &quot;argc&quot; indicates numbers of paras passed by the command-line; parameter &quot;argv&quot; indicates specific paras accordingly. */ struct Eipdebuginfo info; cprintf(&quot;Stack backtrace:\n&quot;); uint32_t *ebp = (uint32_t*)read_ebp(); while(ebp) &#123; uint32_t eip = ebp[1]; cprintf(&quot; ebp %x eip %x args &quot;, ebp, eip); cprintf(&quot;%08.x &quot;, *(ebp+2));//这里提一下指针的用法，指导书中有讲解 cprintf(&quot;%08.x &quot;, *(ebp+3)); cprintf(&quot;%08.x &quot;, *(ebp+4)); cprintf(&quot;%08.x &quot;, *(ebp+5)); cprintf(&quot;%08.x\n&quot;, *(ebp+6)); ebp = (uint32_t*)*(ebp); &#125; return 0;&#125; Exercise 12 对每一个%eip，尝试着给出其文件名称，函数名称和行号。这些信息都属于调试的信息。实验要做的是找到这些调试信息，并按照规定格式将它们输出。这里需要了解STAB符号表的概念。首先查看下kern/kernel.ld链接脚本。发现了有关_STAB_*的两个信息————.stab和.stabstr。其中stab是今天的重点。kern/kdebug.c中的宏定义说明了stab和stabstr的关系。 1234extern const struct Stab __STAB_BEGIN__[]; // Beginning of stabs tableextern const struct Stab __STAB_END__[]; // End of stabs tableextern const char __STABSTR_BEGIN__[]; // Beginning of string tableextern const char __STABSTR_END__[]; // End of string table 再看一下inc/stab.h对stab定义的数据结构:12345678// Entries in the STABS table are formatted as follows.struct Stab &#123; uint32_t n_strx; // index into string table of name 该项对应的在stabstr节内的索引偏移 uint8_t n_type; // type of symbol 该项描述的符号类型 重点关注 uint8_t n_other; // misc info (usually empty) uint16_t n_desc; // description field 源文件的行号 重点关注 uintptr_t n_value; // value of symbol 地址值 重点关注&#125;; 通过objdump -G obj/kern/kernel来查看当前ELF文件中的符号表信息。见下图: 仔细观察上图，发现每一列的分类就是按照stab数据结构分类的。重点关注一下n_type这个关键字，它表示该描述项的符号类型，上图中出现有很多SO，FUN…等符号类型。将这些列单独列出来进行对比: 很明显SO指的是文件名，FUN指的是函数名。注意这是objdump对应的符号表，JOS对符号表有自己定义的数据结构见inc/stab.h。输出的顺序都是按照地址来排序的，很整齐。所以stab_binsearch()查找函数原理也就猜的差不多了，这些调试信息和相应地址的关系是通过符号表来连接的。当然所有的这些知识都可以通过kern/kdebug.c这个文件中对stab的注释（见过最全的注释了）学习到。所以我们最后分析一下这个文件:整个文件一共有两个函数debuginfo_eip和stab_binsearch。JOS建立了一个数据结构Eipdebuginfo用来存放调试信息，debuginfo_eip调用stab_binsearch函数完成一个实例化的Eipdebuginfo，所有的输出信息其实最后都存储在这个实例中。12345678910struct Eipdebuginfo &#123; const char *eip_file; // Source code filename for EIP int eip_line; // Source code linenumber for EIP const char *eip_fn_name; // Name of function containing EIP int eip_fn_namelen; // Length of function name uintptr_t eip_fn_addr; // Address of start of function int eip_fn_narg; // Number of function arguments&#125;; stab_binsearch(const struct Stab *stabs, int *region_left, int *region_right, int type, uintptr_t addr)函数本质上就是一个二分查找。type指的就是符号表项的符号类型，该函数每次查找的时候都需要确定查找的符号类型。我们需要完成的部分是行号，通过检查inc/stab.h文件，很容易知道行号的宏定义是S_LINE。二分查找失败的标志就是LeftA &gt; rightA。所以代码也很简单了:1234567// Your code here. stab_binsearch(stabs, &amp;lline, &amp;rline, N_SLINE, addr); if(lline &lt;= rline)&#123; info-&gt;eip_line = stabs[lline].n_desc; //确定行号 &#125;else &#123; return -1; &#125; 最后将monitor的命令补充完整就更简单了:12345678add :debuginfo_eip(eip, &amp;info); cprintf(&quot;\t%s:%d: %.*s+%d\n&quot;, info.eip_file, info.eip_line, info.eip_fn_namelen, info.eip_fn_name, info.eip_fn_addr);to kern/monitor.c/mon_backtrace()add : &#123;&quot;backtrace&quot;, &quot;Display each stack frame called&quot;, mon_backtrace &#125;,to kern/monitor/commands[] 运行结果见下图: 实验过程中有几处细节涉及到编译器的优化，因为还不是很了解编译链接的细节和原理，所以被我忽略掉了。至此Lab1结束。]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>MIT 6.828</tag>
        <tag>OS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mit6.828(Fall 2018) Lab0]]></title>
    <url>%2F2018%2F11%2F05%2FMit6-828-Fall-2018-Lab0%2F</url>
    <content type="text"><![CDATA[Lab0Abstract 从8086汇编实验之后，前后两周的时间勉强通过Lab1。最大的感触是基础太差:对C语言的理解，对程序编译链接本质的理解，对GDB等工具的使用……当然也包括弱弱的英语理解能力。导致完成Lab1用了这么久的时间。但是这次触动中却又多了一丝见山不是山，见山又是山的感觉。主要体现在我对操作系统的理解最终都回归到代码上来。比如printf函数的实现就涉及C语言中变参的特性。有理由相信这种血浓于水的关系在后续的Lab中还会进一步加强，所以我也希望这会是我学习OS最完美的方法论——————Talk is cheap, show me the code.。截止到Lab1，整个学习的过程显得很清晰————就是通过调试kernel的反汇编代码来理解运行原理并加以修改。Lab0是我在实验过程中掉进的坑，查阅的资料和逐渐点亮的技能树，缩短实验前的准备时间对理解OS本身还是很有帮助的。 6.828实验环境的搭建 虚拟机环境: Ubuntu14.4 (32位) 仿真器: Qemu git clone https://github.com/mit-pdos/6.828-qemu.git qemu 实验代码: Lab git clone https://pdos.csail.mit.edu/6.828/2018/jos.git lab 虚拟机环境32位，因为JOS就是32位的操作系统。仿真器使用MIT进行patched过的(见上链接)。原因是实验中分页机制是有意修改过的，使用patched version的话在后面Exercise中不需要手动转换地址。关于实验代码，默认熟悉Git和MakeFile。每做完一个Exercise可以使用make grade进行测试。在整个实验环境搭建的过程中，可能会因为虚拟机发型版本的不同而出现不同的链接库丢失，Google一下。详细的搭建过程见Tools Guide 关于6.828 MIT的OS课程。学习共有三条主线:Lectures,Readings,Labs。当然最重要的就是Labs。关于剩余的两部分，主要围绕一个叫做xv6的小型OS展开的。简单来讲，这是一个麻雀虽小五脏俱全的OS。有Documents和Source Code两份资料。知乎上评价很高，有人将其翻译成为中文版本上传至Github.XV6_Ch，传说看懂源码之后可以超神……做Lab的过程中，课程会提供大量的Readings来阅读，当然都是英文的。详细见Reference。 80386汇编和内联汇编AT&amp;T-80386 在之前的汇编实验中，我们学习了16位的Intel-8086汇编。而在32位机器上需要使用32位的80386汇编语言。虽然对于Linux来说，8086和80386的机器是有很大的差别的，主要体现在实模式和保护模式上。但是就语言本身而言，更多的是递进的关系而语法差别并不大。目前还没有遇到保护模式相关的障碍。x86的汇编主要有两种格式:Intel和AT&amp;T。6.828使用的是AT&amp;T,而实际上Linux中的汇编也是后者居多。汇编语言本身主要有指令集Instruction Set和伪指令Directives两大部分内容。当然最全的文献是Intel自家的Documents，不过我觉得有些太杂和多了。下面的的资料在实验过程中帮了我很多。值得细看。 MIT——pcasm-book。 Wikipedia——x86 Instruction Set Oracle——x86 Assembler Directives 内联汇编 因为操作系统本身就是和硬件打交道最频繁的系统软件，有些地方需要使用到汇编来简单粗暴的完成工作。内联汇编就是嵌入在C语言中的汇编语言，格式和原来的有很大的不同。不过IBM的那份资料可以解决一大半问题，也是难得的中文文档…… MIT——Brennan’s Guide to Inline Assembly IBM——汇编语言开发指南 ELF文件 实名Diss网上各种对ELF的讲解，故意弄混section和segment的概念。加上对二进制工具使用的不熟练，让我一度以为链接的难度系数是整个实验过程中最高的……直到我看到CSAPP中关于链接部分的讲解。 编译驱动程序 Compiler driver指的是从C文件变成二进制文件的机器操作过程。我们从两个角度理解这个过程:机器运行的角度和C文件类型变化的角度。编译器和汇编器将多个C文件编译成相应的多个可重定位目标文件，也就是平时的.o文件，这种文件由不同的代码节和数据节构成，节在原文中是section。而链接器将多个.o文件链接成为一个可执行目标文件也就是平时的二进制文件。见下图: 熟悉一个程序的第一步是关注其输入输出。一句话总结链接器的功能:以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的可以加载和运行的可执行目标文件作为输出。站在机器的角度，编译器和汇编器将ASCII格式的C文件编译成为字节块section的集合，而链接器做的就是将不同可重定位目标文件中的各种sections做归类，确定被链接块的运行时的内存位置。这是重点，目标文件纯粹是字节块的集合，而链接器本身对程序也所知甚少，她做的仅仅是对字节文件做处理，将多个文件的字节块放到了一个文件中。 链接过程 链接器做两件事: 符号解析: 输入文件的符号引用都对应到其定义上。 重定位: 编译器和汇编器生成的文件地址都是从0开始的，并没有和内存挂上关系。而链接器将这些不同的section定位到内存中的一个地址。也就是其加载地址。重点关注第二步重定位，本质上就是将多个可重定位文件中同类型的.section合并为一个大的聚合节。但是注意这时候还没有segment的概念,聚合节还是叫做.section。我查阅了CSAPP的英文版，全书第一次提到segment 是在链接器部分的最末尾，也就是讲重定位的时候。下面是原文: 明显看到segment还是内存的概念而非可执行文件中的部分。所以从头到尾链接过程都没有生成过segment这样一种东西，其只是多个sections对应于内存中的映射。全书对链接部分的讲解也很少提及segment，所以我们对链接的理解最小单位应该是section，链接过程就是对section进行操作;而最后重定位的时候将多个大的section映射到一段内存中，映射的单位才是segment。现在看下图就很清楚了: 从文件类型的角度来看: 目前我们谈到的ELF文件有可重定位目标文件和可执行目标文件。可以使用二进制工具ELF文件进行分析。关于链接更本质的过程还是很复杂的，Lab1后面会有一部分和符号表相关的实验，建议先详细看看CSAPP和下面提供的资料。 MIT——The definitive standard for the ELF format Wikipedia——Executable and Linkable Format ELF中文文档——ELF.Ch二进制分析工具6.828中主要使用objdump，基本工具可以通过man来查看用法，这里列出几个最常见的参数。 Objdump 对目标文件进行分析，在Linux平台上有三种object file:Relocatable object File,Executable object File,Shared object File，一直没搞懂为啥都叫object File。不过因为这三种目标文件对应于链接的不同阶段，所以对于链接过程本质的理解直接影响这里使用这个二进制分析工具。 -f Display file headers -d Disassembly -h Section headers -x All headers -S Display source code Nm 列出目标文件中的符号表内容，应该和重定位关系密切。 阅读源码CLI工具 虽然我是Emacs党，但是不得不承认VIM在进行文本操作的时候还是更方便:)一些。 VIM-Ctags 这个就很强大了，用于在tags文件所在的根目录下寻找函数声明和宏定义，在阅读源码的时候基本上不知道的定义和关键字都可以使用Ctags来进行定位，非常实用。安装成功之后，在工程目录下面执行命令ctags -R *对当前目录递归建立索引，会生成tags文件。在源码中遇到未见过的函数便将光标放在其上Ctrl - }即可跳转到其声明的位置。Ctrl - o自动返回。 VIM_TagList 这个实际上没怎么用，功能是在VIM中打开目录树，便于程序员操作。可以先留下来，进一步观察。 Tmux 这又是一个神器，终端分屏功能强大，有window,pannel等概念。和on-my-zsh配合使用简直了。不愿意折腾的话也可以在bash下直接使用。我们在GDB调试OS的时候使用她作为分屏工具，需要在家目录下加入配置文件~/.tmux.conf。 VimGrep 用于在指定目录下进行全局搜索并在另一个窗口打开;关键字sample;在vim命令模式下执行命令； :vim/sample/% | copen 当前文件搜索 :vim/sample/* | copen 当前目录搜索 :vim/sample/ ../** | copen 从上一级目录开始递归搜索 :vim/sample path1/** path2/** | copen 多路径搜索 : cclose 关闭当前搜索]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>MIT 6.828</tag>
        <tag>OS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编语言（王爽）ch5]]></title>
    <url>%2F2018%2F10%2F16%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%EF%BC%88%E7%8E%8B%E7%88%BD%EF%BC%89ch5%2F</url>
    <content type="text"><![CDATA[第五部分:中断IIAbstract CPU实现I/O功能的两个问题:从何处获得外设的输入？如何解决外设输入随时可能发生的问题？首先外设芯片内部有若干寄存器，CPU将这些寄存器当做端口来访问。外设的输入输出不直接送入CPU和内存而是通过这些寄存器。第二，CPU通过外中断控制I/O的随时性。 端口 CPU可以直接读写三个地方的数据: 内部寄存器 内存单元 端口CPU通过端口地址来定位不同的端口，最多可以定位64KB个端口，则端口地址范围为0~65535。端口的读写指令in和out。只能使用al和ax来存放对端口进行读写的数据。 外中断 外中断是由相关芯片发送给CPU中的。分为可屏蔽中断和不可屏蔽中断。不可屏蔽中断指那些CPU一定需要响应的中断，这种中断很少，中断类型码固定为2。大多数外中断指的是可屏蔽中断。CPU要不要响应可屏蔽中断完全取决于状态寄存器的IF位。为1则响应，否则不响应。8086中手动设置IF的指令: sti:设置为1 cli:设置为0 实验 编写9号中断例程PC机键盘的处理过程 键盘中有一个芯片扫描每一个键的状态——按下还是松开。按下产生一个扫描码称为通码，松开也产生一个扫描码称为断码。断码=通码+80h。扫描码被送到60h端口中。int 9h是BIOS提供的不可屏蔽中断。一旦CPU收到该信号: 读出60h端口的扫描码 如果是字符键的扫描码，将该扫描码和所对应的字符码送入内存中的BIOS键盘缓存区(16个字单元)。如果是控制键(Ctrl)和切换键(CapsLock)的扫描码，则将其转变为状态字节写进内存中存储状态字节的单元。 对键盘系统进行相关的控制。 实验 在屏幕中间依次显示”a”~”z”,在显示的过程中按下Esc键后改变颜色。实验有意思的地方在于:因为键盘上所有的键都会触发int 9h中断，需要在保证其他键无效的情况下，Esc键触发中断————就相当于出现了两个中断例程，两个中断向量。更有趣的是需要这两个中断同时有效，在一个int 9h中断下！方法也很简单，就是使用if_else判断扫描码。当然汇编中没有if_else。 中断向量和中断例程 键盘无论是哪一个键当然只会触发int 9h中断这个不会变。不过得分别写例程: 12345678910111213141516171819202122232425262728assume cs:code stack segment db 128 dup (0) stack ends data segment dw 0,0 data ends code segment start: mov ax,stack mov ss,ax mov sp,128 mov ax,data mov ds,ax mov ax,0 mov es,ax push es:[9*4] pop ds:[0] push es:[9*4+2] pop ds:[2] mov word ptr es:[9*4],offset int 9 mov es:[9*4+2],cs 上面的代码主要就是设置了中断向量表。可以看到讲原来的int 9h中断例程地址保存在ds:0,ds:2地址处，换上新的例程地址cs:(offset int 9)。新的例程代码:12345678910111213141516171819202122int9: push ax push bx push es in al,60h pushf call dword ptr ds:[0] ;这里的实际上模拟了int 9中断例程的功能，实现子程序中的调用 cmp al,1 jne int9ret ;下面是Esc例程代码 mov ax,0b800h mov es,ax inc byte ptr es:[160*12+40*2+1] ;改变属性值，改变颜色int9ret:pop es pop bx pop ax iret 其中cmp al,1和jne int9ret就相当于if_else的功能。在主程序中有了栈，栈在中断例程中的主要作用就是保护现场，分析一下: 需要保护最开始的int 9h的中断向量号 因为在显示字符的主程序中，ax,es,bx都保存了重要的中间参数，所以需要保护除此之外,栈并没有起到什么作用。这样看下来其实源程序也简单了不少。]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>i386</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编语言（王爽）ch4]]></title>
    <url>%2F2018%2F10%2F12%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%EF%BC%88%E7%8E%8B%E7%88%BD%EF%BC%89ch4%2F</url>
    <content type="text"><![CDATA[第四部分:中断IAbstract 在之前的实验中，我们所编写的汇编程序从编译到运行出结果都很顺利。这个过程映射到CPU层面就是CS:IP的跳转唯一取决于汇编程序员的代码。CSAPP将这个过程称为程序控制流。而中断则是将这种流程打断，建立更复杂的异常控制流。中断分为内中断和外中断两种。 内中断中断产生 8086CPU使用中断类型码来标识中断信息的来源。中断类型码为一个字节型数据，可以表示256种中断信息的来源————具体指的是产生中断信息的事件，简称中断源。下面是8086中4种常见的中断源及其中断类型码: 除法错误: 0 单步执行: 1 执行into指令: 4 执行int n指令: n 中断过程 CPU获得中断类型码之后，需要跳转到该中断类型码对应的中断处理程序中进行处理。如何跳转呢？使用中断向量表。而跳转通常意味着改变CPU的状态，所以需要使用栈来保存现场。所以识别，保存和跳转就是中断过程主要干的事儿————其中识别由硬件完成！中断向量表保存在内存0000:0000到0000:03FF的这1KB单元里。一个表项存放一个中断向量————也就是中断处理程序的地址入口。占4个字节，高地址放段地址，低地址放偏移地址。 识别下图是一张8086的内存分布图: 从内存0开始，所以存储N号中断源对应的中断向量的偏移地址的内存地址为:0000:4N，存储N号中断源对应的中断向量的段地址的内存地址为:0000：4N+2。看下图: 跳转和保存 获得中断类型码 标志寄存器的值入栈: pushf 设置标志寄存器第8位TF和第9位IF的值位0: TF=0,IF=0 CS的内容入栈: push CS IP的内容入栈: push IP 通过中断类型码获取入口地址: (IP)=(N*4),(CS)=(N*4+2) 最后一步执行结束后，CPU开始执行由程序员编写的中断处理程序 中断处理 所谓中断处理程序就是操作系统对各种中断的反应。 由于CPU随时可能检测到中断，所以中断处理程序必须一直存储在内存某段空间中。下面的实验就是通过来实现内中断处理程序。 0号中断即除法溢出错误。 123mov ax, 1000hmov bh,1div bh 该除法指令在执行的过程中会发生溢出错误，导致产生0号中断从而引发中断过程。 实验 编写0号中断的处理程序 中断类型码:0 中断处理程序: 选择0000：0200到0000：02ff这256个Bytes内存的区域来存放 中断向量表: 0号中断的段地址0000:0002偏移地址0000:0000安装处理程序do0 得确保中断处理程序不会变动，所以选择一块合适的内存区域将其安装进去。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546 assume cs:code code segment start: mov ax,cs mov ds,ax mov si,offset do0 ;设置ds:si指向被拷贝的程序地址 mov ax,0 mov es,ax ;设置es:di指向拷贝的目的地址 mov di,200h mov cx,offset do0end-offset do0 ;设置需要拷贝的代码长度度 cld ;设置传输方向为正 rep movsb /* 设置中断向量表 */ mov ax, 4c00h int 21h do0: jmp short do0start db &quot;overflow!&quot; do0start: mov ax,cs mov ds,ax mov si,200h ;设置ds:si指向字符串 mov ax,0b800h mov es,ax mov di,12*160+36*2 ;设置es:di指向显存空间的中间位置 mov cx,9 ;字符串的长度 s: mov al,[si] mov es:[di],al inc si add di,2 loop s mov ax,4c00h int 21h do0end: nop code ends end start 设置中断向量号 当中断发生的时候，确保0号中断的处理程序跳转地址是上一个设置好的地址。 1234mov ax,0mov es,axmov word ptr es:[0*4],200hmov word ptr es:[0*4+2], 0 验证 注意，在跳转到中断处理程序之前，所有的CPU现场已经入栈保存好了，而跳转过程本身也是硬件过程，所以我们所做的仅仅只是设置好跳转的地址和该地址相应的处理代码。经过实验发现DOSBox的和传统的DOS还是有一些区别的，这里用一个小实验验证中断:首先我们直接在debug下面将0号中断向量号改写成为0000:0200处，然后在另一块内存0200:0000中写进了会引发0号中断的代码:然后修改好了CS:IP地址并开始执行: 现象单步执行,可以看到CS:IP的值在执行到div bh的时候，立马从0200:0005变成了0000:0002!,我写的中断处理mov cx,ffff也被执行！然后一直执行到结束退出。实验的整个过程实际上就是做了一个跳转，然后我们仔细对比一下跳转前后寄存器值的差距:会发现除了CS:IP有变化之外，SS:SP大小也有变化，这是CPU保存现场的缘故————从00F7到00FD共3个字对应CS，IP和TF；而且状态寄存器EI也变为DI,估计也和TF和IF相关;因为我们的中断处理直接退出程序所以栈中的数据没有派上用场，不过如果需要返回源程序做一些操作的时候栈就会起到恢复的作用。我还尝试过在中断产生的时候查看栈中的内容，但是每次指令刚执行就被强制退出……不知道为什么。不过这是下一个实验的内容了。另外，这里可以回过头看一下ch2中关于栈的那个猜测，基本上没有毛病。 1号中断 在CPU保存现场的时候，对状态寄存器压栈，并且将其中两个状态位设置为零:TF=0;IF=0;主要是因为当CPU每执行完一条指令的时候，就会去查看状态寄存器的TF位是否为1，如果是则引发1号中断————单步中断。整个中断的过程和其他的没有什么区别，作者提到debug -t的单步执行功能，实际上就是通过debug调用1号中断对CPU进行控制。这里的控制主要体现在中断处理程序上————比如debug -t就是设置寄存器的值显示在屏幕上。那为什么要在处理之前又将TF设置为零呢？注意前面的每执行完一条指令的意思，CPU在执行中断处理程序的时候是不能响应其他中断的，TF=0是防止在过程中递归的陷入。 但是在有些特殊情况下中断的产生，CPU不见得马上处理。比如mov ss, ax和MOV sp, 10这两条设置堆栈的指令，在前面的实验中出现过。 int 指令中断例程 int n是一种很重要的内中断。n是中断类型码，该条指令功能就是可以引发中断过程。执行如下: 取终端类型码n 标志寄存器入栈，IF=0,TF=0 push cs,push ip (IP)=(n4),(CS)=(n4+2)注意一下这里的压栈顺序，后面的实验中会有用到。一般情况下，系统会将一些具有一定功能的子程序，以中断处理程序的方式提供给应用程序调用，通常就是使用int指令。将这些自己编写的中断处理程序叫做中断例程。 编写loop中断例程 在屏幕中间显示80个“！”。这个程序一看就知道需要使用到loop指令，但是该指令到底是如何实现的呢？我们知道跳转指令实际上就是改变CS:IP的值，而给定次数的跳转和给定目标的跳转合在一起就会比较麻烦。跳转指令是靠两个标号之间的相对位移而不是靠标号的地址这一点很重要。我们用cx存放循环次数，用bx存放相对位移。先看一下例程代码: 123456789101112131415161718192021assume cs:codecode segment start:mov ax,0b800h mov es,ax mov di,160*12 mov bx,offset s-offset se mov cx,80s: mov byte ptr es:[di],&apos;!&apos; add di,2 /* int 7ch例程代码:如果（cx）!=0,跳转到标号s处 */se: nop mov ax,4c00 int 21h code endsend start 至此，应该已经完全可以看懂这些汇编程序。可是核心的功能呢？如下:跳转到标号s处需要知道s的段地址和偏移地址。先来分析一下在执行int 7ch之后发生了什么？画得不好凑活着看吧:)x86中的栈是一个满堆栈。首先标志寄存器入栈，然后对se标号的CS:IP压栈。因为代码只有一个段，所以se的段地址和s的段地址一样。而bx中存储了s-se，所以对于s来说:bx+se就是它自己的偏移量。而se的偏移量就是栈中的IP。所以思路顺下来了。可以写代码了。 1234567lp: push bp mov bp,sp dec cx ;cx-- jcxz lpret ;if(cx=0) (cs:ip)=lpret add [bp+2],bx ;重点lpret: pop bp iret 上述代码中add [bp+2],bx就是前面刚顺下来的算法实现。将栈中的IP修改称为s的偏移地址。这里的重点是iret指令，这个指令和跳转指令经常组合在一起共同使用，相当于pop ip,pop cs,popf这三条指令的和。上述代码就是在栈中修改好CS:IP的值，然后使用iret出栈执行。 结果 本次实验的过程实际上就是分为两部分:安装例程和执行例程。 安装例程对于7ch中断类型码来说，对应的中断例程地址应该在0000:01f0。我们首先将中断例程写进该地址，然后修改中断向量表项。 1234567891011121314151617181920212223242526272829303132333435363738assume cs:code code segmentstart: mov ax,cs mov ds,ax mov si,offset do0 mov ax,0 mov es,ax mov di,200h mov cx,offset do0end-offset do0 ;将中断例程写进对应的地址中 cld rep movsb mov ax,0 ;这4行代码修改中断向量表 mov es,ax mov word ptr es:[7ch*4],200h mov word ptr es:[7ch*4+2],0 mov ax,4c00h int 21hdo0: ;这是中断例程 push bp mov bp,sp dec cx jcxz lpret add [bp+2],bxlpret: pop bp iret do0end: nop code endsend start 我们将上述代码保存为sample.asm然后编译连接。然后执行sample.exe:上图分别是地址0000:0200处的中断例程，和0000:01f0处的中断向量表。可以看到成功写入内存。 执行例程 执行程序就是调用int 7ch这个例程看是否有效。我们将执行程序保存为demo.asm编译连接。 12345678910111213141516171819assume cs:codecode segmentstart: mov ax,0b800h mov es,ax mov di,160*12 ;确定显存的地址 mov bx,offset s-offset se mov cx,80s: mov byte ptr es:[di],&apos;!&apos; add di,2 int 7ch ;在这里int指令充当了loop的功能se: nop mov ax,4c00h int 21h code endsend start 然后执行demo.exe,看现象: 总结 这是最简单的一个例程，不过我们可以因此得知跳转指令和栈的重要性! BIOS和DOS所提供的中断例程 关于BIOS和DOS已经很熟悉了，从计算机加电开始，CS:IP会自动跳转到ffff:0000的地址执行程序，到底执行的是啥？有两大部分:自检程序和初始化程序。初始化程序将建立BIOS所支持的中断向量。BIOS中的中断例程主要有: 外部中断和内部中断的中断例程 用于对硬件设备进行I/O操作的中断例程 其他和硬件系统相关的中断例程 自检和初始化完成之后，调用int 19h进行操作系统的引导。而DOS也有自己的中断例程，这些中断例程是操作系统提供给程序员的资源。另外，DOS和硬件设备相关的中断例程一般都是调用了BIOS的中断例程。每一个中断例程都是由很多的子程序构成的。不管是BIOS还是DOS的中断例程都通过ah来传递内部子程序的编号。 BIOS中断例程int 10h用来设置和字符和光标。见代码: 看现象: 下面是代码: 1234567891011121314151617181920assume cs:codecode segment mov ah,2 ;置光标 mov bh,0 ;第0页 mov dh,5 ;行号 mov dl,12 ;列号 int 10h mov ah,9 ;在光标位置显示字符 mov al, &apos;a&apos; ;字符 mov bl,11001010b ;颜色属性 mov bh,0 ;第0页 mov cx,5 ;字符重复个数 int 10h mov ax,4c00h int 21h code ends end DOS中断例程 DOS中断int 21h，之前一直使用4ch00参数即程序返回功能。参数ah=9表示调用第21h号中断例程的9号子程序:在光标位置上显示字符串.看现象:下面是代码: 1234567891011121314151617181920212223assume cs:codedata segment db &apos;Dos is shit!&apos;,&apos;$&apos; data endscode segmentstart: mov ah,2 mov bh,0 mov dl,12 int 10h ;BIOS 中断例程 mov ax,data mov ds,ax mov dx,0 mov ah,9 int 21h ;DOS中断例程 mov ax,4c00h int 21hcode endsend start]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>i386</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编语言（王爽）ch3]]></title>
    <url>%2F2018%2F10%2F11%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%EF%BC%88%E7%8E%8B%E7%88%BD%EF%BC%89ch3%2F</url>
    <content type="text"><![CDATA[第三部分:指令核心Abstract内存寻址 内存是啥？计算机从诞生之初，就面临着CPU和I/O之间，与存储器之间越来越明显的速度矛盾。正是因此才诞生了内存，cache等一系列缓冲的加速设备。你可以理解为内存是CPU获取运行代码的唯一途径，注意这里的内存指的是内存地址空间。CPU如何访问内存？当然是使用寄存器;那寄存器如何访问内存？这就涉及到内存寻址的知识。寻址的方式有很多种类 ，不过归结到底都是段地址+偏移地址。段地址存储在段寄存器中，而偏移地址的方式就有很多种。见下图: 需要注意的是: 上图中的idata表示立即数，[]表示偏移地址。(ax)表示寄存器ax的内容。 []中的除了立即数之外，只有bx,si,di和bp四个寄存器可以进行寻址，其他的寄存器不行。 [bp]的段寄存器默认是ss。 编译器masm和调试器debug两个工具对于mov ax,[idata]中的idata处理不同，编译器会将其识别为idata,所以在使用编译器的时候这种形式应该写成mov ax,ds:[idata] 数据处理(总结性质) 计算机处理的最终还是数据，那么就有两个最基本的问题: 处理的数据在什么地方？ 要处理的数据有多长？问题一绝大部分机器指令都是进行数据处理的指令，处理大致分为三类:读取，写入，运算。在机器指令这一层来说并不关心数据的值，而关心指令执行前一秒，将要处理的数据所在的位置。指令在执行之前，所要处理的数据可以在三个地方:CPU内部，寄存器，端口。问题二8086指令可以处理两种尺寸的数据:Byte和Word。所以在机器指令中需要指明是字操作和字节操作。 通过寄存器指明:ax，al等 用操作符X ptr指明内存单元的长度，X是word或者byte。比如:mov byte ptr ds:[0],1。 还有一些默认的操作比如栈操作默认为字操作。 指令详解伪指令补充 db 定义字节型数据 dw 定义字型数据 dd 定义双字节型数据 dup 和前面三个伪指令结合使用，用来进行数据的重复。db 3 dup(1,2,3)表示定义的三个字节型数据分别为1,2,3。 LOOP循环指令 主要进行两步操作，（cx）=(cx)-1，判断cx中的值。不为零则转至标号处执行程序，如果为零则向下执行。可见cx中的值影响了loop指令的执行结果。 1234mov cx,循环次数s: 循环执行的程序段 loop s JMP转移指令 可以修改IP，或同时修改CS和IP的指令统称为转移指令。概括地讲，转移指令就是可以控制CPU执行内存中某处代码的的指令。根据修改的方式，只修改IP的称为段内转移，修改IP和CS的称为段间转移。由于转移指令对IP的修改范围不同，段内转移又分为:短转移（8位）和近转移（16位）。不同的转移方式，其基本的原理确实相同的。 1-JMP short offset转移指令值得注意的点就是offset指的不是确定的地址，而是从标号到指令之间的位移。(IP)=(IP)+8位位移，段内短转移的位移范围位8位有符号数，用补码表示。offset处的地址-JMP指令后的第一个字节的地址。 1-JMP near ptr offset(IP)=(IP)+16位位移 ,段内近转移的位移范围是16位有符号数，用补码表示。原理和前者一样。 2-JMP far ptr offset前面的几种类型地址都是通过offset和位移，而接下来的几种是在寄存器和内存中的给定IP或者CS。内存地址单元可以用任意的寻址方式得到。（CS）=标号所在段的段地址，（IP）=标号所在段中的偏移地址 。段间转移，会发现其跳转地址实际上是在指令中的offset的地址。和前两个还是有区别的。 2-JMP 16位reg最基础的跳转指令，只是修改IP=16位的寄存器中内容。 2-JMP word ptr 内存单元地址比如:jmp word ptr ds:[0]中ptr后面的就是一个地址，jmp word ds:[0],0后面跟两个地址。注意（CS）=(内存地址单元+2)，（IP）=（内存地址单元）。 2-jcxz该指令为有条件转移指令，所有的有条件转移指令都是短转移。方式为:if((cx)==0)jmp short offset另外，所有的loop循环指令都是短转移。 CALL和RET指令ret(近转移) 书中说ret指令用栈中的数据修改IP中的内容。之前对栈有一个分类，这里的栈是满递减堆栈。所以由此可知堆栈指针SP一直指向最后一个压栈的数据。ret指令实际上把堆栈中的最后一个数据作为自己跳转的偏移地址。方式如下:(IP)=((ss)*16+(sp)),(sp)=(sp)+2从上面也可以看出来这两条指令等同于:pop IP retf(远转移) 书中说retf指令用栈中的数据修改IP和CS中的内容。类似:(IP)=((ss)*16+(sp)),(sp)=(sp)+2（CS）=（（ss）*16+(sp)）,(sp)=(sp)+2这四条指令等同于:pop IP,pop CS call指令 call指令不能实现短转移，但是其转移的原理和jmp指令相同。如下：(sp)=(sp)-2,((ss)*16+(sp))=(IP),(IP)=(IP)+16位位移这几条指令相当于:push IP和jmp near ptr offset call和ret指令(子程序) 先看一段代码: 12345678910111213assume cs:codecode segmentstart: mov ax,1 mov cx,3 call s mov bx,ax mov ax,4c00h int 21h s: add ax,ax loop s retcode endsend start 程序执行到call s的时候，IP指向了后面的一条指令，然后CPU执行call s指令————将当前的IP（mov bx,ax的地址）压栈，然后修改为s地址。然后子程序开始执行，执行结束之后执行ret指令————从栈中弹出一个值，将CS:IP的值指向mov bx,ax。然后返回为原来的地址。这两条指令为子程序的调用提供了可能。 标志寄存器 寄存器是汇编程序员解决问题的最有利的手段，不仅仅在于可以存储数据，还具有辅助指令执行的功能。标志寄存器就是如此，用来存储CPU执行指令的某些执行结果。存储的信息称为“程序状态字PSW”。状态寄存器的每一位都有具体的含义。下面分别介绍: ZF标志零标志位，相关指令执行结束如果结果为0，zf=1；如果不为0，zf=0. PF标志 奇偶标志位，相关指令执行结束如果结果的所有bit位中1的个数为偶数，pf=1,否则pf=0. SF标志 符号标志位，相关指令执行结束如果结果为负，sf=1；否则sf=0。该标志是CPU对有符号数计算结果的一种记录。 CF标志 进位标志位，在进行无符号数运算的时候，它记录了运算结果的最高有效位向更高位的进位值，或从更高位的借位值。 OF标志 溢出标志位，在进行有符号数运算的时候，记录了是否发生溢出。 标志寄存器在Debug中的使用 标志寄存器是按照有意义的各个标志位单独表示的。如下。下图是已知的标志位的表示: 其他指令（总结性质）还有很多的指令比如MOV,CMP，abc等。但这里并不打算详细讲解每一条指令，就像书中所说:汇编语言只是载体，目的在于理解机器运行的原理和方式。至此，我们已经学习了寄存器，内存,汇编指令，并且掌握了一个正常的程序控制流在机器层面的运行过程。接下来的内容，就属于操作系统的层面，引入异常控制流，也就是在正常的执行过程中有外界干扰的情况，这是理解整个OS的重点，也是我写这几篇技术博客的主要学习目的。(mit6.828中的汇编大同小异，只是指令集换成了AT&amp;T的格式)。 实验7 寻址方式在结构化数据访问中的应用实验9 根据材料编程实验10 编写子程序]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>i386</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编语言（王爽）ch2]]></title>
    <url>%2F2018%2F10%2F04%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%EF%BC%88%E7%8E%8B%E7%88%BD%EF%BC%89ch2%2F</url>
    <content type="text"><![CDATA[第二部分:汇编结构Abstract汇编语言的结构寄存器和内存之间 汇编语言是由不同的段构成的，这些段的功能各异不过主要分为指令和数据两部分。运行汇编代码的意思就是将汇编代码加载到内存中，通过寄存器完成内存和CPU之间的交互。从这个角度看寄存器就是汇编的一种手段。但是寄存器和内存实际上是两个完全不一样的硬件设备，暂时先不考虑性能和速率差的问题。指令和数据到底是如何在不同的存储单元之间传递的。字节存储和字存储就是两种解决办法，在8086中寄存器是16位的(16位为一字)，而存储器的最小存储单元是8位也就是一个字节，所以如果在一些读写中需要用到字存储而不是字节存储的话，就需要两块连续的内存单元才能完成数据的传输，而且是高地址存放字的高位字节，低地址存放字的低位字节。要读写一块内存单元的时候，必须先要给出这个内存单元的地址。在实验1中我们知道了CPU使用段地址+偏移地址的方式来进行寻址。而实现这些功能的就是一些具有特殊功能的寄存器。这里提到的是最简单的也最常使用的两种类型: CS+IP————在任意时刻CPU将CS:IP指向的内容当做指令执行。 DS+[idata]————DS通常用来存放需要访问的数据的段地址。这里主要介绍汇编语言的结构，对应到寄存器和内存寻址的方式后面会讲。数据段将一段内存当做数据段，是我们在编程的时候的一种安排，可以在具体操作的时候，用ds存放数据的段地址，再根据相关指令访问数据段中的具体单元。 代码段 从硬件角度讲，CPU只认被CS:IP指向的内存单元中的内容为指令。要让CPU执行我们放在代码段的指令，必须要将CS:IP指向所定义的代码段中的第一条指令的首地址。 栈段 栈是一种先进后出的数据结构，这是最基本的栈的概念。这里讲到的栈指的是内存区域。从操作系统的角度讲一个线程需要分配一个栈(stack)。相对应的一个进程需要分配一个堆(heap)。栈的大小在分配的时候就已经确定好了，其作用主要是存放一些局部和确定的变量和数据。 关于栈也有两个寄存器:SS:SP。换句话讲CPU如何知道一段内存区域是不是栈？栈顶的段地址放在SS中，而偏移地址放在SP中。任意时刻，SS:SP指向栈顶元素。这是规定。 另外，上微机原理课的时候，老师讲到栈的分类: 向高地址生长的称为递增堆栈。 向地地址生长的称为递减堆栈。 地址延伸主要的影响就是内存中的大端寻址和小端寻址。 &lt;img src=&quot;4.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; alt=&quot;&quot;&gt; 堆栈指针指向最后压入堆栈的有效数据项，叫做满堆栈。 堆栈指针指向下一个待压入数据的空位置，叫做空堆栈。 栈指令 在i386的指令集中，栈操作都是以字为单位的。 push执行过程1. SP=SP-2; 2. 向`SP:SS`指向的内存字单元中送入数据; pop执行过程1. 从`SP:SS`指向的内存字单元中读取数据; 2. SP=SP+2; 段的概念 之前讨论过关于段这个概念。我认为，还是因为在编程的时候可以通过一个系统化的结构来统一汇编语言的实现逻辑。使得这些指令看上去便于管理和协调合作。至于其物理实现，其实就是CPU的寻址方式决定的。书本中有一段话特别经典，我摘抄如下: 123456789101112131415161718192021222324比如我们将10000H~1001F安排为代码段，并在里面存储如下代码: MOV ax,1000H MOV ss,axMOV sp,0020H //初始化栈顶MOV ax,csMOV ds,ax //设置数据段段地址MOV ax,[0]add ax,[2]add bx,[4]add bx,[6]push axpush bxpop axpop bx 设置CS=1000，IP=0.这段代码就会被执行，但是可以看到在这段代码中，我们又将 10000H~1001FH安排为栈段和数据段。 可见不管我们如何安排，CPU将内存中的某段内存当做代码，是因CS:IP指向了那里。 CPU将某段内存当做栈，是因为SS:SP指向了那里。我们一定要清楚，什么是我们的安排， 以及如何让CPU按我们的安排行事。要非常清楚CPU的工作机理，才能在控制CPU按照我们 的安排运行的时候做到游刃有余。 一段内存，可以既是代码的存储空间，又是数据的存储空间，还可以是栈空间，也可以什么都不是。 关键是在于CPU中寄存器的设置，机CS，IP，SS，SP，DS的指向。 多个段的统一 以前写的汇编都是单个段，并且主要是代码段。如果内存中的一段汇编代码需要包含多个数据段，代码段，栈段。该如何设计才能保证程序正常运行呢？我们应该有一个概念，就是所谓和CPU对应的程序一定是CS:IP指向的内存地址。所以实际上这个问题是在问保证CS:IP正确指向程序的前提下，如何让数据段，栈段合理的加进来？这里有个伪指令的概念，伪指令主要是为汇编器提供一些编译的前提信息比如从哪里开始执行代码，其他的段的起始地址在哪里。所以问题也就解决了。 如何保证CS:IP指向代码段: end和end start 如何定义一个段: code segment和code ends 如何将段寄存器和段相对应: assume cs:code 汇编语言的编译、连接过程及其工具的使用 这部分详细见书上。 源程序组成 一个汇编程序的源程序由汇编指令和伪指令构成。汇编指令指的是编译成为机器指令最终为CPU所执行的代码。伪指令没有相对应的机器指令，主要是由编译器来执行的指令。 编译、链接、执行 源程序经过编译成为可重定位文件，然后经过链接成为可执行文件。可执行文件是可以直接在操作系统中执行的。上述两种文件都属于ELF格式的文件，ELF是Linux下面的一种文件格式，具体的细节在后面的操作系统中会谈到，这里只是了解。 编程（edit）————&gt;1.asm————&gt;编译(masm)————&gt;1.obj————&gt;链接(link)————&gt;1.exe————&gt;加载(shell)————&gt;内存中的程序————&gt;运行(CPU) 工具进阶debug -d 第一个实验中使用的debug工具，通过各种参数来对寄存器和内存进行读写。比如d 段地址:偏移地址指令会列出指定内存单元中的内容。但是debug也是一个程序，而能定位内存地址的方式在8086中只有段寄存器可以做到,实际上debug就是通过将地址写入段寄存器中的方式来进行内存寻址。这个原理适用于所有的参数。而使用的这个段寄存器正是DS寄存器。根据这个原理，就可以通过修改寄存器来进阶使用这些命令，比如:-r ds,:1000,-d ds:0这段代码就表示查看从1000：0开始的内存空间中的内容。这里主要是认识到段寄存器DS的寻址功能，为之后的寻址方式打基础。 debug -p 在整个实验中，debug工具是经常要使用的。debug有两种用法，一种就是使用a参数直接写入程序然后调试。还有一种就是直接调试exe文件。第一种之前一直在用，第二种方式加载的过程有一些不一样，ds段寄存器中存放着该程序的段地址，因为偏移为零所以DS:0就是所加载程序的首地址。而加载进来的程序前256字节存放的是一段通信程序，所以真正的代码是在(DS+10H:0):0开始的。每一段汇编指令都需要以mov ax,4c00H，int 21H结尾。在调试到int 21H的时候需要使用P命令执行。出现Program terminated normally程序正常退出。 实验2 用机器指令和汇编指令编程 这个实验很有意思，一共有两部分: 第一部分使用a将下面的汇编指令写入内存，然后使用T命令调试。如下: 1234567mov ax,2000mov ss,axmov sp,10mov ax,3123push axmov ax,3366push ax 会发现在单步调试的时候，在mov ss,ax之后的下一条指令竟然不是mov sp,10。但是查看寄存器的时候发现实际上这条执行已经被执行结束了。这是第一个现象。 第二部分 对上面的代码继续调试，如下：会发现最开始对栈初始化之后，到执行到mov ss,ax指令的时候，查看原来的栈段内容竟然不再是零，且这些数字还都是和段寄存器相关的。 总结 下图是接下来的每一步后栈段中的内存变化。 可以看到的现象是:开始的时候栈中是没有数据的，栈桢SP指向2000:0010的位置。在mov ss,ax和mov sp,10这两步执行结束之后，发现栈中已经有数据了，这里称为初始化。初始化的一共有6字节的数据:4个字节为CS:IP，还有两字节在栈底确定为01A3H。之后的每一条栈操作的指令执行结束之后栈中的CS:IP值也会跟着变化，这说明每一次指令都有可能产生一次中断。但是在栈底的01A3H一直没有变化估计应该是中断相关。在正式压栈操作的过程中发现最开始初始化过的那些数据并没有被压到栈底，这就意味着堆栈指针SP应该还在栈底，然后真正有数据项压栈的时候才会SP-=2操作。 小实验就上面的三个现象，我在想仅仅是初始化的过程就已经占据了一大半栈空间，那如果将栈大小调整成为8字节的。那会出现什么情况？ 我将mov sp,10改成mov sp,08；然后准备了8字节数据，所以栈会被压满。这时候我想看看现象。这是一张初始化的图: 这是末尾压栈满了的图: 因为书上关于中断的详细讲解在第四部分，所以这里只是一个猜测。现象中随着栈不断被压满，之前初始化的那些数据都被挤出去了，具体去哪了不知道。那6个字节的数据到底有什么用也不知道。 猜测不过可以知道的是初始化栈帧的时候会有参数压到栈里，参数有CS:IP和中断向量号，其中CS:IP还在不断变化。而随着栈中的数据越来越多，栈中的这6个字节的参数被慢慢挤出。难道这6个字节不重要吗，或者说只是在初始化的时候用了一下？但是过程中这些参数一直也在变化，所以不可能不重要.不过这些数据之所以放到栈中的原因一定不是为了存储，否则就不会被随便挤出。结合第一部分实验，mov sp,10是紧跟着前一条指令执行的，所以我能想到的唯一一个合理的解释就是:这些参数是在指令执行过程中直接使用的，而执行过程对shell屏蔽不可见，所以在栈中数据越来越多的时候这些参数还可以随意的移动位置并且被抛弃，这些参数是过程中使用的参数，而这个过程就是中断！至于中断到底是什么，到第4章再详细学习吧。 实验3 用编程、编译、连接、跟踪 最后一个实验查看PSP（就是加载开始前256字节）的内容。使用u来查看汇编好像又和中断有关系。]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>i386</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编语言（王爽）ch1]]></title>
    <url>%2F2018%2F10%2F02%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%EF%BC%88%E7%8E%8B%E7%88%BD%EF%BC%89ch1%2F</url>
    <content type="text"><![CDATA[第一部分:硬件模型Abstract硬件基础 全书的核心在使用汇编语言进行编程，老师在第一章就抽象出了完整的编程模型供汇编程序员参考————冯诺依曼结构。 CPU只是一个运算单元，只有提供了数据和指令才可以正常运行，而数据和指令存储在内存中。那CPU和内存如何进行交互？ 存储单元的地址（地址） 读/写操作（控制） 读/写的具体数据（数据） 答案是总线，地址总线决定了CPU的寻址能力；数据总线决定了CPU一次能够处理多少数据；控制总线决定了CPU对外部器件的控制能力。这里的外部器件指的是除内存外的其他存储单元比如VGA等。所以在模型内部实际上还有一层抽象————那就是由系统中所有的存储单元组成的统一的逻辑存储器。实际上CPU面向的就是这个逻辑存储器，书中叫它内存地址空间。 以上就是整个书中抽象出来最简单的编程模型，王爽老师在一开始就定下这本书的基调————不是讲CPU和外设的物理结构《微机原理和接口》，也不是讲整个计算机系统的结构和功能《组成原理》。学习汇编语言是利用固有的硬件体系和特有的指令集进行编程从而对硬件系统进行控制。 固有的硬件体系指的是这套CPU+RAM的计算机模型是图灵，冯诺依曼这些先驱们总结出来的一套最适合的结构。而特有的指令集则是说不同的CPU有不同的汇编语言，用x86的汇编语言的原因主要是因为这套指令集只有14个寄存器和1MB(20位地址总线)寻址空间，比较容易掌握。 指令和数据 学习组成的时候就对这两个概念很模糊，但是做实验的过程中其实发现：其实CPU看到的东西就是一堆01而已，真正将这堆01赋予意义的还是我们。换句话说就是数据和指令只是一个应用上的概念，你将它放到PC中它就是地址，而将它放到另外一个寄存器中它可能就直接被用来运算了。从原理上看，主要是不同的寄存器对这些数据赋予了不同的功能。CPU的工作用一句话来概括就是从特定的寄存器中取出data1作为地址，然后把内存中这个地址相对应的data2作为指令进行计算。但是如果我把data1和data2互换一下，其实也是可以的。但是需要考虑到的是data2所代表的地址是不是在内存地址空间的范围之内，我的理解是寄存器，总线，内存中存储数据的位数有可能都是不一样的。但是说到底它们只是来存储数据的，写错最坏的情况也就是CPU跑崩了。 寄存器 8086CPU有14个寄存器，都是16位的。但是这16位的寄存器也可以独立作为两个8位的寄存器使用。 寄存器和内存是汇编程序猿眼中最直观的计算机样子。 汇编层面的CPU 运算器进行信息处理 寄存器进行信息存储 控制器控制各种器件进行工作 内部总线连接各种器件，在它们之间进行数据的传送 8086架构（16位机）具体深究到物理实现就是《组成原理》知识了。 运算器一次最多可以处理16位数据 寄存器的最大宽度为16位 寄存器和运算器之间的通路为16位 汇编层面的内存 CPU在访问内存单元的时候，需要知道内存单元的地址。所有的内存单元构成的存储空间是一个一维的线性空间，每一个内存空间在这个空间上都有唯一的地址，这个惟一的地址就叫做物理地址。CPU首先在内部形成这个物理地址，然后通过地址总线送入存储器。这个地址一定是一个内存单元的物理地址。不同的CPU架构形成地址的方式不一样。 CS:IP 前面提到了8086CPU内部需要形成物理地址，但是8086是16位机————只能处理和传输16位的地址，但是8086的地址总线有20位，所以需要两个16位来共同形成一个20位的地址。 14个寄存器中，CS是段寄存器，存放基地址。而IP存放偏移量。公式:CSx16+IP。 首先需要明白的就是，一个内存单元是8位二进制也叫一个字节。而十六进制的一位可以表示成为二进制的4位。完全只是为了方便才写成16进制的。20位的地址（5位16进制）可以写成4C780H，后面的H表示16进制。一个X进制的数据左移一位，相当于乘以X。所以为了记起来方便一些可以记成CS寄存器的数据左移一位+IP寄存器的值。但是两个寄存器只有16位（4位16进制)，到后面计算的时候需要注意这两个前提，避免溢出。 书中特别强调了对段的理解。这里的段并不是指内存被物理上分成一段一段的。而是因为CPU在管理内存的时候，使用CSx16+IP的方式来进行管理。所以可以将地址连续，起始地址为16的倍数的一组内存单元看成是一个段。重点在于不是所有的起始地址都可以作为段地址————这是因为CSx16决定的。而且因为IP是16位的所以每一个段的长度最大为64KB。 执行过程 在8086机中，任意时刻CPU将CS:IP指向的内容当做指令执行。汇编中使用jmp 段地址:偏移地址对CS:IP进行修改。或者使用jmp 寄存器来修改IP的值。 8086的工作过程 从CS:IP指向的内存单元中读取指令，读取的指令进入指令缓存器。 IP指向下一条指令。 执行指令,从CS:IP中取指令，重复上面的过程。 书中划线 汇编语言和机器语言的差别在于指令的表示方法上。 微机存储器的容量是以字节为最小单位的来计算的。 在内存和磁盘上，数据和指令没有任何区别。 在汇编语言这门课中，我们所面对的是内存地址空间。CPU向这段地址中读写数据实际上就是向相应的物理存储器中读写数据。 内存地址空间的大小受到CPU地址总线宽度的限制。 实验1 查看CPU和内存，用机器指令和汇编指令编程工具介绍 debug是DOS,Windows都提供的实模式（8086方式）程序的调试工具。下面是本次实验将会用到的参数: r (读写寄存器) r查看所有的寄存器的值 r 寄存器名称修改制定寄存器的值 d （读写内存） d 段地址:偏移地址 列出从指定内存单元开始的128个内存单元的内容 d 段地址:起始偏移地址 结尾偏移地址列出在偏移地址范围之内的内存单元的内容 e （读写内存） e 段地址:偏移地址 data1 data2 data3……从特定单元开始讲数据写入内存 e 段地址:偏移地址 回车表示挨个儿修改内存，空格表示默认不修改，回车表示修改结束 e+u+t 使用e参数向内存中写入机器码 使用u 段地址:偏移地址可以将内存中机器码翻译成为汇编语言 t参数执行CS:IP指向的内存地址单元的任何指令，注意修改参数 a a 段地址:偏移地址可以直接使用汇编的格式写入机器指令 实验任务 一共有4个实验。写出来的都是我觉得很有意思且值得讨论的实验。 第二个实验 给出起始地址为2000:0000的三条指令，使用这三条指令计算2的8次方。 &lt;img src=&quot;2.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; alt=&quot;&quot;&gt; 有意思的是这个算法，a += a；如果这里的a是2的话，实际上a+a等于ax2所以可以2的8次方可以通过8次这样的加法完成，但是如果a是其他的值就不行了。 最后两个实验 使用e参数对特定的内存单元进行读写。 这两个实验间接地证明了内存地址空间的存在。 我在向内存B810:0000中写数据的时候，发现显示器上会出现有颜色的字符和表情包，猜想这个地址应该是显存的物理地址。这也说明这里的内存不仅仅指的是主存储器，还有其他的和CPU直接相连的RAM。 ​]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>i386</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编语言（王爽）ch0]]></title>
    <url>%2F2018%2F10%2F02%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%EF%BC%88%E7%8E%8B%E7%88%BD%EF%BC%89ch0%2F</url>
    <content type="text"><![CDATA[Abstract 王爽老师的《汇编语言》是国内的经典教材。学习汇编是为了获得底层编程的体验和理解机器运行程序的机理。所以经典的做法往往不是只针对于某一种指令集，而是以一种指令集为手段来深入理解机器工作的原理，体会一个没有操作系统的编程开发环境。正如书中所讲:编程的平台是硬件而不是操作系统。或许这也是汇编语言真正的价值所在吧。 实验环境 全书的实验都是在8086CPU的体系结构下展开的，这也是Intel第一块16位的处理器。我们有两种办法在自己的计算机上模拟8086:一种是使用WindowsXP系统。一种是采用DOSBox模拟器，第二种比较方便。这里是链接。本书有17个实验，2个课程设计，5个研究试验。我主要是以其中一些实验为章节展开学习。 全书架构 在我看来，全书应该可以分为这么几个部分: 硬件模型Chapter.(1、2)————告诉你汇编编程就是程序员以指令为手段在CPU的寄存器和内存地址空间之间进行数据读写的的过程。 汇编结构Chapter.(3、4)————介绍了完整的汇编程序的组成部分:数据段，代码段、栈段。第4章介绍了汇编程序编译的全过程和基本工具的使用。 指令核心Chapter.(5~11)————从第5章作者开始引进一些新的指令，并且展开来讲汇编程序设计的核心部分。介绍了重点的指令比如操作指令,跳转指令，比较指令等及其用法等，并深入介绍了内存寻址的各种花式用法。 操作系统层面的应用Chapter.(12~17)和操作系统相关的概念比如中断等。 整个学习过程中，寄存器和内存地址空间的读写是贯穿全书的核心，因为所有的操作最终都是产生了对内存或者某一个寄存器的读写。而完成这一切读写功能的就是汇编指令。这也是机器硬件的真正工作原理。虽然这些部分都可以拆开来了解，但是实际上每一部分还有很多的细节和承上启下的概念，我也是站在我理解的角度对这些内容进行了划分，需要注意的是:全书还有很多的细节比如不同的存储单元和数据处理方式，这些都不是单独某一个章节可以完成的而是贯穿全书实验的前提。所以还是需要通读一遍全书来顺这些概念。 搭建实验条件 将下载好的环境包放在~/x86，作为我们的工作目录。 打开DOSBox模拟器。 挂载C盘:mount C ~/x86。 进入C盘:C:。 开始实验:debug。 退出程序quit，退出模拟器exit。 安装成功展示 ​]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>i386</tag>
      </tags>
  </entry>
</search>
